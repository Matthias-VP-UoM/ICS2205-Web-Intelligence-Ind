{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary packages to perform document indexing and querying tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mvass\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mvass\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mvass\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import json\n",
    "import math # for custom TF.IDF measure\n",
    "import random # to choose a random example query (if needed)\n",
    "import numpy as np # to create cosine similarity measure\n",
    "import xml.etree.ElementTree as ET # to extract content from specific XML tag\n",
    "\n",
    "nltk.download (\"punkt\")\n",
    "nltk.download (\"stopwords\")\n",
    "nltk.download (\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Indexing Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting a list of all the documents that are found under the \"dataset\" subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wes2015.d001.naf',\n",
       " 'wes2015.d002.naf',\n",
       " 'wes2015.d003.naf',\n",
       " 'wes2015.d004.naf',\n",
       " 'wes2015.d005.naf',\n",
       " 'wes2015.d006.naf',\n",
       " 'wes2015.d007.naf',\n",
       " 'wes2015.d008.naf',\n",
       " 'wes2015.d009.naf',\n",
       " 'wes2015.d010.naf',\n",
       " 'wes2015.d011.naf',\n",
       " 'wes2015.d012.naf',\n",
       " 'wes2015.d013.naf',\n",
       " 'wes2015.d014.naf',\n",
       " 'wes2015.d015.naf',\n",
       " 'wes2015.d016.naf',\n",
       " 'wes2015.d017.naf',\n",
       " 'wes2015.d018.naf',\n",
       " 'wes2015.d019.naf',\n",
       " 'wes2015.d020.naf',\n",
       " 'wes2015.d021.naf',\n",
       " 'wes2015.d022.naf',\n",
       " 'wes2015.d023.naf',\n",
       " 'wes2015.d024.naf',\n",
       " 'wes2015.d025.naf',\n",
       " 'wes2015.d026.naf',\n",
       " 'wes2015.d027.naf',\n",
       " 'wes2015.d028.naf',\n",
       " 'wes2015.d029.naf',\n",
       " 'wes2015.d030.naf',\n",
       " 'wes2015.d031.naf',\n",
       " 'wes2015.d032.naf',\n",
       " 'wes2015.d033.naf',\n",
       " 'wes2015.d034.naf',\n",
       " 'wes2015.d035.naf',\n",
       " 'wes2015.d036.naf',\n",
       " 'wes2015.d037.naf',\n",
       " 'wes2015.d038.naf',\n",
       " 'wes2015.d039.naf',\n",
       " 'wes2015.d040.naf',\n",
       " 'wes2015.d041.naf',\n",
       " 'wes2015.d042.naf',\n",
       " 'wes2015.d043.naf',\n",
       " 'wes2015.d044.naf',\n",
       " 'wes2015.d045.naf',\n",
       " 'wes2015.d046.naf',\n",
       " 'wes2015.d047.naf',\n",
       " 'wes2015.d048.naf',\n",
       " 'wes2015.d049.naf',\n",
       " 'wes2015.d050.naf',\n",
       " 'wes2015.d051.naf',\n",
       " 'wes2015.d052.naf',\n",
       " 'wes2015.d053.naf',\n",
       " 'wes2015.d054.naf',\n",
       " 'wes2015.d055.naf',\n",
       " 'wes2015.d056.naf',\n",
       " 'wes2015.d057.naf',\n",
       " 'wes2015.d058.naf',\n",
       " 'wes2015.d059.naf',\n",
       " 'wes2015.d060.naf',\n",
       " 'wes2015.d061.naf',\n",
       " 'wes2015.d062.naf',\n",
       " 'wes2015.d063.naf',\n",
       " 'wes2015.d064.naf',\n",
       " 'wes2015.d065.naf',\n",
       " 'wes2015.d066.naf',\n",
       " 'wes2015.d067.naf',\n",
       " 'wes2015.d068.naf',\n",
       " 'wes2015.d069.naf',\n",
       " 'wes2015.d070.naf',\n",
       " 'wes2015.d071.naf',\n",
       " 'wes2015.d072.naf',\n",
       " 'wes2015.d073.naf',\n",
       " 'wes2015.d074.naf',\n",
       " 'wes2015.d075.naf',\n",
       " 'wes2015.d076.naf',\n",
       " 'wes2015.d077.naf',\n",
       " 'wes2015.d078.naf',\n",
       " 'wes2015.d079.naf',\n",
       " 'wes2015.d080.naf',\n",
       " 'wes2015.d081.naf',\n",
       " 'wes2015.d082.naf',\n",
       " 'wes2015.d083.naf',\n",
       " 'wes2015.d084.naf',\n",
       " 'wes2015.d085.naf',\n",
       " 'wes2015.d086.naf',\n",
       " 'wes2015.d087.naf',\n",
       " 'wes2015.d088.naf',\n",
       " 'wes2015.d089.naf',\n",
       " 'wes2015.d090.naf',\n",
       " 'wes2015.d091.naf',\n",
       " 'wes2015.d092.naf',\n",
       " 'wes2015.d093.naf',\n",
       " 'wes2015.d094.naf',\n",
       " 'wes2015.d095.naf',\n",
       " 'wes2015.d096.naf',\n",
       " 'wes2015.d097.naf',\n",
       " 'wes2015.d098.naf',\n",
       " 'wes2015.d099.naf',\n",
       " 'wes2015.d100.naf',\n",
       " 'wes2015.d101.naf',\n",
       " 'wes2015.d102.naf',\n",
       " 'wes2015.d103.naf',\n",
       " 'wes2015.d104.naf',\n",
       " 'wes2015.d105.naf',\n",
       " 'wes2015.d106.naf',\n",
       " 'wes2015.d107.naf',\n",
       " 'wes2015.d108.naf',\n",
       " 'wes2015.d109.naf',\n",
       " 'wes2015.d110.naf',\n",
       " 'wes2015.d111.naf',\n",
       " 'wes2015.d112.naf',\n",
       " 'wes2015.d113.naf',\n",
       " 'wes2015.d114.naf',\n",
       " 'wes2015.d115.naf',\n",
       " 'wes2015.d116.naf',\n",
       " 'wes2015.d117.naf',\n",
       " 'wes2015.d118.naf',\n",
       " 'wes2015.d119.naf',\n",
       " 'wes2015.d120.naf',\n",
       " 'wes2015.d121.naf',\n",
       " 'wes2015.d122.naf',\n",
       " 'wes2015.d123.naf',\n",
       " 'wes2015.d124.naf',\n",
       " 'wes2015.d125.naf',\n",
       " 'wes2015.d126.naf',\n",
       " 'wes2015.d127.naf',\n",
       " 'wes2015.d128.naf',\n",
       " 'wes2015.d129.naf',\n",
       " 'wes2015.d130.naf',\n",
       " 'wes2015.d131.naf',\n",
       " 'wes2015.d132.naf',\n",
       " 'wes2015.d133.naf',\n",
       " 'wes2015.d134.naf',\n",
       " 'wes2015.d135.naf',\n",
       " 'wes2015.d136.naf',\n",
       " 'wes2015.d137.naf',\n",
       " 'wes2015.d138.naf',\n",
       " 'wes2015.d139.naf',\n",
       " 'wes2015.d140.naf',\n",
       " 'wes2015.d141.naf',\n",
       " 'wes2015.d142.naf',\n",
       " 'wes2015.d143.naf',\n",
       " 'wes2015.d144.naf',\n",
       " 'wes2015.d145.naf',\n",
       " 'wes2015.d146.naf',\n",
       " 'wes2015.d147.naf',\n",
       " 'wes2015.d148.naf',\n",
       " 'wes2015.d149.naf',\n",
       " 'wes2015.d150.naf',\n",
       " 'wes2015.d151.naf',\n",
       " 'wes2015.d152.naf',\n",
       " 'wes2015.d153.naf',\n",
       " 'wes2015.d154.naf',\n",
       " 'wes2015.d155.naf',\n",
       " 'wes2015.d156.naf',\n",
       " 'wes2015.d157.naf',\n",
       " 'wes2015.d158.naf',\n",
       " 'wes2015.d159.naf',\n",
       " 'wes2015.d160.naf',\n",
       " 'wes2015.d161.naf',\n",
       " 'wes2015.d162.naf',\n",
       " 'wes2015.d163.naf',\n",
       " 'wes2015.d164.naf',\n",
       " 'wes2015.d165.naf',\n",
       " 'wes2015.d166.naf',\n",
       " 'wes2015.d167.naf',\n",
       " 'wes2015.d168.naf',\n",
       " 'wes2015.d169.naf',\n",
       " 'wes2015.d170.naf',\n",
       " 'wes2015.d171.naf',\n",
       " 'wes2015.d172.naf',\n",
       " 'wes2015.d173.naf',\n",
       " 'wes2015.d174.naf',\n",
       " 'wes2015.d175.naf',\n",
       " 'wes2015.d176.naf',\n",
       " 'wes2015.d177.naf',\n",
       " 'wes2015.d178.naf',\n",
       " 'wes2015.d179.naf',\n",
       " 'wes2015.d180.naf',\n",
       " 'wes2015.d181.naf',\n",
       " 'wes2015.d182.naf',\n",
       " 'wes2015.d183.naf',\n",
       " 'wes2015.d184.naf',\n",
       " 'wes2015.d185.naf',\n",
       " 'wes2015.d186.naf',\n",
       " 'wes2015.d187.naf',\n",
       " 'wes2015.d188.naf',\n",
       " 'wes2015.d189.naf',\n",
       " 'wes2015.d190.naf',\n",
       " 'wes2015.d191.naf',\n",
       " 'wes2015.d192.naf',\n",
       " 'wes2015.d193.naf',\n",
       " 'wes2015.d194.naf',\n",
       " 'wes2015.d195.naf',\n",
       " 'wes2015.d196.naf',\n",
       " 'wes2015.d197.naf',\n",
       " 'wes2015.d198.naf',\n",
       " 'wes2015.d199.naf',\n",
       " 'wes2015.d200.naf',\n",
       " 'wes2015.d201.naf',\n",
       " 'wes2015.d202.naf',\n",
       " 'wes2015.d203.naf',\n",
       " 'wes2015.d204.naf',\n",
       " 'wes2015.d205.naf',\n",
       " 'wes2015.d206.naf',\n",
       " 'wes2015.d207.naf',\n",
       " 'wes2015.d208.naf',\n",
       " 'wes2015.d209.naf',\n",
       " 'wes2015.d210.naf',\n",
       " 'wes2015.d211.naf',\n",
       " 'wes2015.d212.naf',\n",
       " 'wes2015.d213.naf',\n",
       " 'wes2015.d214.naf',\n",
       " 'wes2015.d215.naf',\n",
       " 'wes2015.d216.naf',\n",
       " 'wes2015.d217.naf',\n",
       " 'wes2015.d218.naf',\n",
       " 'wes2015.d219.naf',\n",
       " 'wes2015.d220.naf',\n",
       " 'wes2015.d221.naf',\n",
       " 'wes2015.d222.naf',\n",
       " 'wes2015.d223.naf',\n",
       " 'wes2015.d224.naf',\n",
       " 'wes2015.d225.naf',\n",
       " 'wes2015.d226.naf',\n",
       " 'wes2015.d227.naf',\n",
       " 'wes2015.d228.naf',\n",
       " 'wes2015.d229.naf',\n",
       " 'wes2015.d230.naf',\n",
       " 'wes2015.d231.naf',\n",
       " 'wes2015.d232.naf',\n",
       " 'wes2015.d233.naf',\n",
       " 'wes2015.d234.naf',\n",
       " 'wes2015.d235.naf',\n",
       " 'wes2015.d236.naf',\n",
       " 'wes2015.d237.naf',\n",
       " 'wes2015.d238.naf',\n",
       " 'wes2015.d239.naf',\n",
       " 'wes2015.d240.naf',\n",
       " 'wes2015.d241.naf',\n",
       " 'wes2015.d242.naf',\n",
       " 'wes2015.d243.naf',\n",
       " 'wes2015.d244.naf',\n",
       " 'wes2015.d245.naf',\n",
       " 'wes2015.d246.naf',\n",
       " 'wes2015.d247.naf',\n",
       " 'wes2015.d248.naf',\n",
       " 'wes2015.d249.naf',\n",
       " 'wes2015.d250.naf',\n",
       " 'wes2015.d251.naf',\n",
       " 'wes2015.d252.naf',\n",
       " 'wes2015.d253.naf',\n",
       " 'wes2015.d254.naf',\n",
       " 'wes2015.d255.naf',\n",
       " 'wes2015.d256.naf',\n",
       " 'wes2015.d257.naf',\n",
       " 'wes2015.d258.naf',\n",
       " 'wes2015.d259.naf',\n",
       " 'wes2015.d260.naf',\n",
       " 'wes2015.d261.naf',\n",
       " 'wes2015.d262.naf',\n",
       " 'wes2015.d263.naf',\n",
       " 'wes2015.d264.naf',\n",
       " 'wes2015.d265.naf',\n",
       " 'wes2015.d266.naf',\n",
       " 'wes2015.d267.naf',\n",
       " 'wes2015.d268.naf',\n",
       " 'wes2015.d269.naf',\n",
       " 'wes2015.d270.naf',\n",
       " 'wes2015.d271.naf',\n",
       " 'wes2015.d272.naf',\n",
       " 'wes2015.d273.naf',\n",
       " 'wes2015.d274.naf',\n",
       " 'wes2015.d275.naf',\n",
       " 'wes2015.d276.naf',\n",
       " 'wes2015.d277.naf',\n",
       " 'wes2015.d278.naf',\n",
       " 'wes2015.d279.naf',\n",
       " 'wes2015.d280.naf',\n",
       " 'wes2015.d281.naf',\n",
       " 'wes2015.d282.naf',\n",
       " 'wes2015.d283.naf',\n",
       " 'wes2015.d284.naf',\n",
       " 'wes2015.d285.naf',\n",
       " 'wes2015.d286.naf',\n",
       " 'wes2015.d287.naf',\n",
       " 'wes2015.d288.naf',\n",
       " 'wes2015.d289.naf',\n",
       " 'wes2015.d290.naf',\n",
       " 'wes2015.d291.naf',\n",
       " 'wes2015.d292.naf',\n",
       " 'wes2015.d293.naf',\n",
       " 'wes2015.d294.naf',\n",
       " 'wes2015.d295.naf',\n",
       " 'wes2015.d296.naf',\n",
       " 'wes2015.d297.naf',\n",
       " 'wes2015.d298.naf',\n",
       " 'wes2015.d299.naf',\n",
       " 'wes2015.d300.naf',\n",
       " 'wes2015.d301.naf',\n",
       " 'wes2015.d302.naf',\n",
       " 'wes2015.d303.naf',\n",
       " 'wes2015.d304.naf',\n",
       " 'wes2015.d305.naf',\n",
       " 'wes2015.d306.naf',\n",
       " 'wes2015.d307.naf',\n",
       " 'wes2015.d308.naf',\n",
       " 'wes2015.d309.naf',\n",
       " 'wes2015.d310.naf',\n",
       " 'wes2015.d311.naf',\n",
       " 'wes2015.d312.naf',\n",
       " 'wes2015.d313.naf',\n",
       " 'wes2015.d314.naf',\n",
       " 'wes2015.d315.naf',\n",
       " 'wes2015.d316.naf',\n",
       " 'wes2015.d317.naf',\n",
       " 'wes2015.d318.naf',\n",
       " 'wes2015.d319.naf',\n",
       " 'wes2015.d320.naf',\n",
       " 'wes2015.d321.naf',\n",
       " 'wes2015.d322.naf',\n",
       " 'wes2015.d323.naf',\n",
       " 'wes2015.d324.naf',\n",
       " 'wes2015.d325.naf',\n",
       " 'wes2015.d326.naf',\n",
       " 'wes2015.d327.naf',\n",
       " 'wes2015.d328.naf',\n",
       " 'wes2015.d329.naf',\n",
       " 'wes2015.d330.naf',\n",
       " 'wes2015.d331.naf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the file path for all documents\n",
    "docs_file_path = \"dataset/docs-raw-texts\"\n",
    "\n",
    "# Getting the documents found under the path set above\n",
    "docs = [f for f in os.listdir(docs_file_path)]\n",
    "\n",
    "# Printing the filenames of the documents (for testing)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Declaring a function to parse a document and extract the data from its < raw > tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to parse the XML from a document and extract the content from < raw > tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doc_xml(xml_file_path):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Getting the content from the <raw> tag in the XML document\n",
    "    raw_data = root.find(\".//raw\").text\n",
    "\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing all the documents found in the dataset subfolder. The content of the < raw > tag in each document is stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to store the content of the < raw > tag of each document\n",
    "docs_xml = []\n",
    "\n",
    "# Looping through the list of documents\n",
    "for doc in docs:\n",
    "    # Setting the file path of each document\n",
    "    xml_file_path = docs_file_path+ '/' +str(doc)\n",
    "    \n",
    "    # Extracting the xml data using the parse_doc_xml() function declared earlier\n",
    "    raw_data = parse_doc_xml(xml_file_path)\n",
    "    \n",
    "    # Adding the extracted content to the list\n",
    "    docs_xml.append(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the contents of the raw tag - for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernard Mandeville and the Fable of the Bees.\n",
      "\n",
      "Bernard Mandeville’s – The Fable of Bees.  On November 15, 1670, Dutch philosopher, political economist and satirist Bernard Mandeville was born. He became famous for The Fable of the Bees, a satire that suggests many key principles of economic thought, including division of labor and the “invisible hand“, seventy years before these concepts were more thoroughly elucidated by Adam Smith. Not very much is known about the life of Bernard Mandeville. He probably grew up in Rotterdam, Netherlands and was the son of a physician. He enrolled at Leiden University and produced his thesis De brutorum operationibus in 1689. In it, Mandeville advocated the Cartesian theory of automatism among animals. He received his degree in medicine in 1691 and his disputation was titled De chylosi vitiata. He became a well known and respected physician and produced several literary works as well, which were considered just as successful. The Grumbling Hive was probably published in 1705 and in 1714, it was again published under the famous name of The Fable of The Bees: or, Private Vices, Public Benefits. Next to the mentioned poem, a detailed discussion is included in the book. It consists numerous key principles of economic thought, such as the division of labour and the famous invisible hand. Mandeville describes a well working community of bees until the bees suddenly turn into honest and virtuous beings. Their community collapses due to the lack of the desire for personal benefits. Mandeville explained that vice was necessary for economic prosperity, which was a quite scandalous point of view. Mandeville and also Adam Smith expressed that individual’s collective actions may lead to a public benefit. However, Smith believed in a virtuous self-interest which results in invisible co-operation and that there was no need for someone to garner the benefit. Mandeville however thought that politicians had to ensure that the people’s passions really resulted in public benefits. Back in the day, Mandeville’s ideas were seen as degrading in concerns of the human nature. At yovisto, you may be interested in a video lecture on Adam Smith and the Wealth of Nations by Professor James Paradis.\n"
     ]
    }
   ],
   "source": [
    "print(docs_xml[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Tokenising the documents' content (from the < raw > tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bernard', 'Mandeville', 'and', 'the', 'Fable', 'of', 'the', 'Bees', '.', 'Bernard', 'Mandeville', '’', 's', '–', 'The', 'Fable', 'of', 'Bees', '.', 'On', 'November', '15', ',', '1670', ',', 'Dutch', 'philosopher', ',', 'political', 'economist', 'and', 'satirist', 'Bernard', 'Mandeville', 'was', 'born', '.', 'He', 'became', 'famous', 'for', 'The', 'Fable', 'of', 'the', 'Bees', ',', 'a', 'satire', 'that', 'suggests', 'many', 'key', 'principles', 'of', 'economic', 'thought', ',', 'including', 'division', 'of', 'labor', 'and', 'the', '“', 'invisible', 'hand', '“', ',', 'seventy', 'years', 'before', 'these', 'concepts', 'were', 'more', 'thoroughly', 'elucidated', 'by', 'Adam', 'Smith', '.', 'Not', 'very', 'much', 'is', 'known', 'about', 'the', 'life', 'of', 'Bernard', 'Mandeville', '.', 'He', 'probably', 'grew', 'up', 'in', 'Rotterdam', ',', 'Netherlands', 'and', 'was', 'the', 'son', 'of', 'a', 'physician', '.', 'He', 'enrolled', 'at', 'Leiden', 'University', 'and', 'produced', 'his', 'thesis', 'De', 'brutorum', 'operationibus', 'in', '1689', '.', 'In', 'it', ',', 'Mandeville', 'advocated', 'the', 'Cartesian', 'theory', 'of', 'automatism', 'among', 'animals', '.', 'He', 'received', 'his', 'degree', 'in', 'medicine', 'in', '1691', 'and', 'his', 'disputation', 'was', 'titled', 'De', 'chylosi', 'vitiata', '.', 'He', 'became', 'a', 'well', 'known', 'and', 'respected', 'physician', 'and', 'produced', 'several', 'literary', 'works', 'as', 'well', ',', 'which', 'were', 'considered', 'just', 'as', 'successful', '.', 'The', 'Grumbling', 'Hive', 'was', 'probably', 'published', 'in', '1705', 'and', 'in', '1714', ',', 'it', 'was', 'again', 'published', 'under', 'the', 'famous', 'name', 'of', 'The', 'Fable', 'of', 'The', 'Bees', ':', 'or', ',', 'Private', 'Vices', ',', 'Public', 'Benefits', '.', 'Next', 'to', 'the', 'mentioned', 'poem', ',', 'a', 'detailed', 'discussion', 'is', 'included', 'in', 'the', 'book', '.', 'It', 'consists', 'numerous', 'key', 'principles', 'of', 'economic', 'thought', ',', 'such', 'as', 'the', 'division', 'of', 'labour', 'and', 'the', 'famous', 'invisible', 'hand', '.', 'Mandeville', 'describes', 'a', 'well', 'working', 'community', 'of', 'bees', 'until', 'the', 'bees', 'suddenly', 'turn', 'into', 'honest', 'and', 'virtuous', 'beings', '.', 'Their', 'community', 'collapses', 'due', 'to', 'the', 'lack', 'of', 'the', 'desire', 'for', 'personal', 'benefits', '.', 'Mandeville', 'explained', 'that', 'vice', 'was', 'necessary', 'for', 'economic', 'prosperity', ',', 'which', 'was', 'a', 'quite', 'scandalous', 'point', 'of', 'view', '.', 'Mandeville', 'and', 'also', 'Adam', 'Smith', 'expressed', 'that', 'individual', '’', 's', 'collective', 'actions', 'may', 'lead', 'to', 'a', 'public', 'benefit', '.', 'However', ',', 'Smith', 'believed', 'in', 'a', 'virtuous', 'self-interest', 'which', 'results', 'in', 'invisible', 'co-operation', 'and', 'that', 'there', 'was', 'no', 'need', 'for', 'someone', 'to', 'garner', 'the', 'benefit', '.', 'Mandeville', 'however', 'thought', 'that', 'politicians', 'had', 'to', 'ensure', 'that', 'the', 'people', '’', 's', 'passions', 'really', 'resulted', 'in', 'public', 'benefits', '.', 'Back', 'in', 'the', 'day', ',', 'Mandeville', '’', 's', 'ideas', 'were', 'seen', 'as', 'degrading', 'in', 'concerns', 'of', 'the', 'human', 'nature', '.', 'At', 'yovisto', ',', 'you', 'may', 'be', 'interested', 'in', 'a', 'video', 'lecture', 'on', 'Adam', 'Smith', 'and', 'the', 'Wealth', 'of', 'Nations', 'by', 'Professor', 'James', 'Paradis', '.']\n"
     ]
    }
   ],
   "source": [
    "# Creating a list to store the tokens from each document\n",
    "xml_docs_tokens = []\n",
    "\n",
    "# Looping through each item in the docs_xml list\n",
    "for xml_part in docs_xml:\n",
    "    # Extracting the different tokens from the text within each element in the list\n",
    "    data_tokens = nltk.tokenize.word_tokenize(xml_part)\n",
    "    \n",
    "    # Adding the tokens to the new list\n",
    "    xml_docs_tokens.append(data_tokens)\n",
    "\n",
    "# Printing the tokens that got extracted for a specific document (for testing purposes)\n",
    "print(xml_docs_tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Extraction of document index terms\n",
    "\n",
    "### Step 3.1 - Performing case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bernard', 'mandeville', 'and', 'the', 'fable', 'of', 'the', 'bees', '.', 'bernard', 'mandeville', '’', 's', '–', 'the', 'fable', 'of', 'bees', '.', 'on', 'november', '15', ',', '1670', ',', 'dutch', 'philosopher', ',', 'political', 'economist', 'and', 'satirist', 'bernard', 'mandeville', 'was', 'born', '.', 'he', 'became', 'famous', 'for', 'the', 'fable', 'of', 'the', 'bees', ',', 'a', 'satire', 'that', 'suggests', 'many', 'key', 'principles', 'of', 'economic', 'thought', ',', 'including', 'division', 'of', 'labor', 'and', 'the', '“', 'invisible', 'hand', '“', ',', 'seventy', 'years', 'before', 'these', 'concepts', 'were', 'more', 'thoroughly', 'elucidated', 'by', 'adam', 'smith', '.', 'not', 'very', 'much', 'is', 'known', 'about', 'the', 'life', 'of', 'bernard', 'mandeville', '.', 'he', 'probably', 'grew', 'up', 'in', 'rotterdam', ',', 'netherlands', 'and', 'was', 'the', 'son', 'of', 'a', 'physician', '.', 'he', 'enrolled', 'at', 'leiden', 'university', 'and', 'produced', 'his', 'thesis', 'de', 'brutorum', 'operationibus', 'in', '1689', '.', 'in', 'it', ',', 'mandeville', 'advocated', 'the', 'cartesian', 'theory', 'of', 'automatism', 'among', 'animals', '.', 'he', 'received', 'his', 'degree', 'in', 'medicine', 'in', '1691', 'and', 'his', 'disputation', 'was', 'titled', 'de', 'chylosi', 'vitiata', '.', 'he', 'became', 'a', 'well', 'known', 'and', 'respected', 'physician', 'and', 'produced', 'several', 'literary', 'works', 'as', 'well', ',', 'which', 'were', 'considered', 'just', 'as', 'successful', '.', 'the', 'grumbling', 'hive', 'was', 'probably', 'published', 'in', '1705', 'and', 'in', '1714', ',', 'it', 'was', 'again', 'published', 'under', 'the', 'famous', 'name', 'of', 'the', 'fable', 'of', 'the', 'bees', ':', 'or', ',', 'private', 'vices', ',', 'public', 'benefits', '.', 'next', 'to', 'the', 'mentioned', 'poem', ',', 'a', 'detailed', 'discussion', 'is', 'included', 'in', 'the', 'book', '.', 'it', 'consists', 'numerous', 'key', 'principles', 'of', 'economic', 'thought', ',', 'such', 'as', 'the', 'division', 'of', 'labour', 'and', 'the', 'famous', 'invisible', 'hand', '.', 'mandeville', 'describes', 'a', 'well', 'working', 'community', 'of', 'bees', 'until', 'the', 'bees', 'suddenly', 'turn', 'into', 'honest', 'and', 'virtuous', 'beings', '.', 'their', 'community', 'collapses', 'due', 'to', 'the', 'lack', 'of', 'the', 'desire', 'for', 'personal', 'benefits', '.', 'mandeville', 'explained', 'that', 'vice', 'was', 'necessary', 'for', 'economic', 'prosperity', ',', 'which', 'was', 'a', 'quite', 'scandalous', 'point', 'of', 'view', '.', 'mandeville', 'and', 'also', 'adam', 'smith', 'expressed', 'that', 'individual', '’', 's', 'collective', 'actions', 'may', 'lead', 'to', 'a', 'public', 'benefit', '.', 'however', ',', 'smith', 'believed', 'in', 'a', 'virtuous', 'self-interest', 'which', 'results', 'in', 'invisible', 'co-operation', 'and', 'that', 'there', 'was', 'no', 'need', 'for', 'someone', 'to', 'garner', 'the', 'benefit', '.', 'mandeville', 'however', 'thought', 'that', 'politicians', 'had', 'to', 'ensure', 'that', 'the', 'people', '’', 's', 'passions', 'really', 'resulted', 'in', 'public', 'benefits', '.', 'back', 'in', 'the', 'day', ',', 'mandeville', '’', 's', 'ideas', 'were', 'seen', 'as', 'degrading', 'in', 'concerns', 'of', 'the', 'human', 'nature', '.', 'at', 'yovisto', ',', 'you', 'may', 'be', 'interested', 'in', 'a', 'video', 'lecture', 'on', 'adam', 'smith', 'and', 'the', 'wealth', 'of', 'nations', 'by', 'professor', 'james', 'paradis', '.']\n"
     ]
    }
   ],
   "source": [
    "# Looping through each item in the xml_docs_tokens_list\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    # Converting each of the data tokens to lowercase\n",
    "    lowercase_data_tokens = [dt.lower() for dt in xml_docs_tokens[i]]\n",
    "    xml_docs_tokens[i] = lowercase_data_tokens\n",
    "\n",
    "# Printing the new extracted tokens from a single document (for testing purposes)\n",
    "print(xml_docs_tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the tokens to only include alphabetical tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bernard', 'mandeville', 'and', 'the', 'fable', 'of', 'the', 'bees', 'bernard', 'mandeville', 's', 'the', 'fable', 'of', 'bees', 'on', 'november', 'dutch', 'philosopher', 'political', 'economist', 'and', 'satirist', 'bernard', 'mandeville', 'was', 'born', 'he', 'became', 'famous', 'for', 'the', 'fable', 'of', 'the', 'bees', 'a', 'satire', 'that', 'suggests', 'many', 'key', 'principles', 'of', 'economic', 'thought', 'including', 'division', 'of', 'labor', 'and', 'the', 'invisible', 'hand', 'seventy', 'years', 'before', 'these', 'concepts', 'were', 'more', 'thoroughly', 'elucidated', 'by', 'adam', 'smith', 'not', 'very', 'much', 'is', 'known', 'about', 'the', 'life', 'of', 'bernard', 'mandeville', 'he', 'probably', 'grew', 'up', 'in', 'rotterdam', 'netherlands', 'and', 'was', 'the', 'son', 'of', 'a', 'physician', 'he', 'enrolled', 'at', 'leiden', 'university', 'and', 'produced', 'his', 'thesis', 'de', 'brutorum', 'operationibus', 'in', 'in', 'it', 'mandeville', 'advocated', 'the', 'cartesian', 'theory', 'of', 'automatism', 'among', 'animals', 'he', 'received', 'his', 'degree', 'in', 'medicine', 'in', 'and', 'his', 'disputation', 'was', 'titled', 'de', 'chylosi', 'vitiata', 'he', 'became', 'a', 'well', 'known', 'and', 'respected', 'physician', 'and', 'produced', 'several', 'literary', 'works', 'as', 'well', 'which', 'were', 'considered', 'just', 'as', 'successful', 'the', 'grumbling', 'hive', 'was', 'probably', 'published', 'in', 'and', 'in', 'it', 'was', 'again', 'published', 'under', 'the', 'famous', 'name', 'of', 'the', 'fable', 'of', 'the', 'bees', 'or', 'private', 'vices', 'public', 'benefits', 'next', 'to', 'the', 'mentioned', 'poem', 'a', 'detailed', 'discussion', 'is', 'included', 'in', 'the', 'book', 'it', 'consists', 'numerous', 'key', 'principles', 'of', 'economic', 'thought', 'such', 'as', 'the', 'division', 'of', 'labour', 'and', 'the', 'famous', 'invisible', 'hand', 'mandeville', 'describes', 'a', 'well', 'working', 'community', 'of', 'bees', 'until', 'the', 'bees', 'suddenly', 'turn', 'into', 'honest', 'and', 'virtuous', 'beings', 'their', 'community', 'collapses', 'due', 'to', 'the', 'lack', 'of', 'the', 'desire', 'for', 'personal', 'benefits', 'mandeville', 'explained', 'that', 'vice', 'was', 'necessary', 'for', 'economic', 'prosperity', 'which', 'was', 'a', 'quite', 'scandalous', 'point', 'of', 'view', 'mandeville', 'and', 'also', 'adam', 'smith', 'expressed', 'that', 'individual', 's', 'collective', 'actions', 'may', 'lead', 'to', 'a', 'public', 'benefit', 'however', 'smith', 'believed', 'in', 'a', 'virtuous', 'which', 'results', 'in', 'invisible', 'and', 'that', 'there', 'was', 'no', 'need', 'for', 'someone', 'to', 'garner', 'the', 'benefit', 'mandeville', 'however', 'thought', 'that', 'politicians', 'had', 'to', 'ensure', 'that', 'the', 'people', 's', 'passions', 'really', 'resulted', 'in', 'public', 'benefits', 'back', 'in', 'the', 'day', 'mandeville', 's', 'ideas', 'were', 'seen', 'as', 'degrading', 'in', 'concerns', 'of', 'the', 'human', 'nature', 'at', 'yovisto', 'you', 'may', 'be', 'interested', 'in', 'a', 'video', 'lecture', 'on', 'adam', 'smith', 'and', 'the', 'wealth', 'of', 'nations', 'by', 'professor', 'james', 'paradis']\n"
     ]
    }
   ],
   "source": [
    "# Removing any non-alphabetical data tokens from each element in the list\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    alpha_data_tokens = [t for t in xml_docs_tokens[i] if t.isalpha()]\n",
    "    xml_docs_tokens[i] = alpha_data_tokens\n",
    "\n",
    "# Printing the new extracted tokens from a single document (for testing purposes)\n",
    "print(xml_docs_tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 - Performing stop-word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bernard', 'mandeville', 'fable', 'bees', 'bernard', 'mandeville', 'fable', 'bees', 'november', 'dutch', 'philosopher', 'political', 'economist', 'satirist', 'bernard', 'mandeville', 'born', 'became', 'famous', 'fable', 'bees', 'satire', 'suggests', 'many', 'key', 'principles', 'economic', 'thought', 'including', 'division', 'labor', 'invisible', 'hand', 'seventy', 'years', 'concepts', 'thoroughly', 'elucidated', 'adam', 'smith', 'much', 'known', 'life', 'bernard', 'mandeville', 'probably', 'grew', 'rotterdam', 'netherlands', 'son', 'physician', 'enrolled', 'leiden', 'university', 'produced', 'thesis', 'de', 'brutorum', 'operationibus', 'mandeville', 'advocated', 'cartesian', 'theory', 'automatism', 'among', 'animals', 'received', 'degree', 'medicine', 'disputation', 'titled', 'de', 'chylosi', 'vitiata', 'became', 'well', 'known', 'respected', 'physician', 'produced', 'several', 'literary', 'works', 'well', 'considered', 'successful', 'grumbling', 'hive', 'probably', 'published', 'published', 'famous', 'name', 'fable', 'bees', 'private', 'vices', 'public', 'benefits', 'next', 'mentioned', 'poem', 'detailed', 'discussion', 'included', 'book', 'consists', 'numerous', 'key', 'principles', 'economic', 'thought', 'division', 'labour', 'famous', 'invisible', 'hand', 'mandeville', 'describes', 'well', 'working', 'community', 'bees', 'bees', 'suddenly', 'turn', 'honest', 'virtuous', 'beings', 'community', 'collapses', 'due', 'lack', 'desire', 'personal', 'benefits', 'mandeville', 'explained', 'vice', 'necessary', 'economic', 'prosperity', 'quite', 'scandalous', 'point', 'view', 'mandeville', 'also', 'adam', 'smith', 'expressed', 'individual', 'collective', 'actions', 'may', 'lead', 'public', 'benefit', 'however', 'smith', 'believed', 'virtuous', 'results', 'invisible', 'need', 'someone', 'garner', 'benefit', 'mandeville', 'however', 'thought', 'politicians', 'ensure', 'people', 'passions', 'really', 'resulted', 'public', 'benefits', 'back', 'day', 'mandeville', 'ideas', 'seen', 'degrading', 'concerns', 'human', 'nature', 'yovisto', 'may', 'interested', 'video', 'lecture', 'adam', 'smith', 'wealth', 'nations', 'professor', 'james', 'paradis']\n"
     ]
    }
   ],
   "source": [
    "# Getting a list of English stop-words\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Removing the stop-words from our tokens from each element in the list\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    filt_data_tokens = [t for t in xml_docs_tokens[i] if (not t in stopwords)]\n",
    "    xml_docs_tokens[i] = filt_data_tokens\n",
    "\n",
    "# Printing the filtered tokens (for testing purposes)\n",
    "print(xml_docs_tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3 - Performing stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bernard', 'mandevil', 'fabl', 'bee', 'bernard', 'mandevil', 'fabl', 'bee', 'novemb', 'dutch', 'philosoph', 'polit', 'economist', 'satirist', 'bernard', 'mandevil', 'born', 'becam', 'famou', 'fabl', 'bee', 'satir', 'suggest', 'mani', 'key', 'principl', 'econom', 'thought', 'includ', 'divis', 'labor', 'invis', 'hand', 'seventi', 'year', 'concept', 'thoroughli', 'elucid', 'adam', 'smith', 'much', 'known', 'life', 'bernard', 'mandevil', 'probabl', 'grew', 'rotterdam', 'netherland', 'son', 'physician', 'enrol', 'leiden', 'univers', 'produc', 'thesi', 'de', 'brutorum', 'operationibu', 'mandevil', 'advoc', 'cartesian', 'theori', 'automat', 'among', 'anim', 'receiv', 'degre', 'medicin', 'disput', 'titl', 'de', 'chylosi', 'vitiata', 'becam', 'well', 'known', 'respect', 'physician', 'produc', 'sever', 'literari', 'work', 'well', 'consid', 'success', 'grumbl', 'hive', 'probabl', 'publish', 'publish', 'famou', 'name', 'fabl', 'bee', 'privat', 'vice', 'public', 'benefit', 'next', 'mention', 'poem', 'detail', 'discuss', 'includ', 'book', 'consist', 'numer', 'key', 'principl', 'econom', 'thought', 'divis', 'labour', 'famou', 'invis', 'hand', 'mandevil', 'describ', 'well', 'work', 'commun', 'bee', 'bee', 'suddenli', 'turn', 'honest', 'virtuou', 'be', 'commun', 'collaps', 'due', 'lack', 'desir', 'person', 'benefit', 'mandevil', 'explain', 'vice', 'necessari', 'econom', 'prosper', 'quit', 'scandal', 'point', 'view', 'mandevil', 'also', 'adam', 'smith', 'express', 'individu', 'collect', 'action', 'may', 'lead', 'public', 'benefit', 'howev', 'smith', 'believ', 'virtuou', 'result', 'invis', 'need', 'someon', 'garner', 'benefit', 'mandevil', 'howev', 'thought', 'politician', 'ensur', 'peopl', 'passion', 'realli', 'result', 'public', 'benefit', 'back', 'day', 'mandevil', 'idea', 'seen', 'degrad', 'concern', 'human', 'natur', 'yovisto', 'may', 'interest', 'video', 'lectur', 'adam', 'smith', 'wealth', 'nation', 'professor', 'jame', 'paradi']\n"
     ]
    }
   ],
   "source": [
    "# Declaring an initialising a stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "#Stemming each token found in the document\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    stemmed_tokens = [stemmer.stem(fdt) for fdt in xml_docs_tokens[i]]\n",
    "    xml_docs_tokens[i] = stemmed_tokens\n",
    "\n",
    "# Printing the stemmed tokens from a single document (for testing purposes)\n",
    "print(xml_docs_tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Build the term by document matrix containing the TF.IDF weight for each term within each document\n",
    "\n",
    "### Step 4.1 - Calculating TF (term frequency) of each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bernard': 4, 'mandevil': 10, 'fabl': 4, 'bee': 6, 'novemb': 1, 'dutch': 1, 'philosoph': 1, 'polit': 1, 'economist': 1, 'satirist': 1, 'born': 1, 'becam': 2, 'famou': 3, 'satir': 1, 'suggest': 1, 'mani': 1, 'key': 2, 'principl': 2, 'econom': 3, 'thought': 3, 'includ': 2, 'divis': 2, 'labor': 1, 'invis': 3, 'hand': 2, 'seventi': 1, 'year': 1, 'concept': 1, 'thoroughli': 1, 'elucid': 1, 'adam': 3, 'smith': 4, 'much': 1, 'known': 2, 'life': 1, 'probabl': 2, 'grew': 1, 'rotterdam': 1, 'netherland': 1, 'son': 1, 'physician': 2, 'enrol': 1, 'leiden': 1, 'univers': 1, 'produc': 2, 'thesi': 1, 'de': 2, 'brutorum': 1, 'operationibu': 1, 'advoc': 1, 'cartesian': 1, 'theori': 1, 'automat': 1, 'among': 1, 'anim': 1, 'receiv': 1, 'degre': 1, 'medicin': 1, 'disput': 1, 'titl': 1, 'chylosi': 1, 'vitiata': 1, 'well': 3, 'respect': 1, 'sever': 1, 'literari': 1, 'work': 2, 'consid': 1, 'success': 1, 'grumbl': 1, 'hive': 1, 'publish': 2, 'name': 1, 'privat': 1, 'vice': 2, 'public': 3, 'benefit': 5, 'next': 1, 'mention': 1, 'poem': 1, 'detail': 1, 'discuss': 1, 'book': 1, 'consist': 1, 'numer': 1, 'labour': 1, 'describ': 1, 'commun': 2, 'suddenli': 1, 'turn': 1, 'honest': 1, 'virtuou': 2, 'be': 1, 'collaps': 1, 'due': 1, 'lack': 1, 'desir': 1, 'person': 1, 'explain': 1, 'necessari': 1, 'prosper': 1, 'quit': 1, 'scandal': 1, 'point': 1, 'view': 1, 'also': 1, 'express': 1, 'individu': 1, 'collect': 1, 'action': 1, 'may': 2, 'lead': 1, 'howev': 2, 'believ': 1, 'result': 2, 'need': 1, 'someon': 1, 'garner': 1, 'politician': 1, 'ensur': 1, 'peopl': 1, 'passion': 1, 'realli': 1, 'back': 1, 'day': 1, 'idea': 1, 'seen': 1, 'degrad': 1, 'concern': 1, 'human': 1, 'natur': 1, 'yovisto': 1, 'interest': 1, 'video': 1, 'lectur': 1, 'wealth': 1, 'nation': 1, 'professor': 1, 'jame': 1, 'paradi': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty lists of dictionaries to calculate TF (term frequency)\n",
    "tf_dict = []\n",
    "\n",
    "# Calculate the frequency of each token in every document\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    doc_dict = dict()\n",
    "    for token in xml_docs_tokens[i]:  # a new token encountered\n",
    "        if token not in doc_dict:\n",
    "            doc_dict.update({token: 1})\n",
    "        else:  # existing token\n",
    "            count = doc_dict.get(token)\n",
    "            new_count = count + 1\n",
    "            doc_dict.update({token: new_count})\n",
    "    tf_dict.append(doc_dict)\n",
    "\n",
    "\n",
    "# Printing the contents of the dictionary (for testing purposes)\n",
    "print(tf_dict[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 - Calculating IDF (inverse document frequency) for each document per term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2.1 - Calculating DF (number of documents containing a specific term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    }
   ],
   "source": [
    "# Setting the num_of_docs variable to be equal to the number of documents found in the docs list\n",
    "num_of_docs = len(docs)\n",
    "\n",
    "# Creating a new dictionary to store the number of times each token appears in its respective document\n",
    "df_dict = dict()\n",
    "\n",
    "# Variable used for every new token encountered\n",
    "previous_i = 0\n",
    "\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    doc_tokens = tf_dict[i].keys()\n",
    "    for token in doc_tokens:\n",
    "        if token not in df_dict:\n",
    "            previous_i = i\n",
    "            df_dict.update({token: 1})\n",
    "        elif token in df_dict and previous_i != i:\n",
    "            count = df_dict.get(token)\n",
    "            new_count = count + 1\n",
    "            df_dict.update({token: new_count})\n",
    "\n",
    "# Printing the number of documents to make sure that it is accurate\n",
    "print(num_of_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2.2 - Calculating N/DF(x), where N stands for the number of documents and x stands for the term for which the process is being done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf_dict = dict()\n",
    "\n",
    "for x in df_dict:\n",
    "    token_df = df_dict[x]\n",
    "    df_new = num_of_docs/token_df\n",
    "    ndf_dict[x] = df_new\n",
    "\n",
    "    \n",
    "# Printing the contents from the dictionary (for testing purposes)\n",
    "#print(ndf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2.3 - Calculating log of the answer for each term calculated previosuly to get IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dict = dict()\n",
    "\n",
    "for x in ndf_dict:\n",
    "    token_ndf = ndf_dict[x]\n",
    "    token_idf = math.log10(token_ndf)\n",
    "    idf_dict[x] = token_idf\n",
    "\n",
    "    \n",
    "# Printing the contents from the dictionary (for testing purposes)\n",
    "#print(idf_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3 - Mutliply TF and IDF together to get weighting for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an list of dictionaries to calculate weighting\n",
    "weighting_dict = tf_dict.copy()\n",
    "\n",
    "for i in range(0, len(weighting_dict)):\n",
    "    for token in weighting_dict[i]:\n",
    "        token_tf = weighting_dict[i].get(token)\n",
    "        token_idf = idf_dict.get(token)\n",
    "        token_weighting = token_tf * token_idf\n",
    "        weighting_dict[i][token] = token_weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the data from any specific document (for testing purposes only) - done in a seperate cell to avoid modifying any values when the above is mistakenly run more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bernard': 7.671072009791025, 'mandevil': 25.19827993775719, 'fabl': 10.079311975102875, 'bee': 15.118967962654313, 'novemb': 2.519827993775719, 'dutch': 2.519827993775719, 'philosoph': 1.9177680024477564, 'polit': 2.0427067390560563, 'economist': 2.519827993775719, 'satirist': 2.519827993775719, 'born': 1.2410743928228898, 'becam': 3.6417159788794, 'famou': 5.753304007343269, 'satir': 2.519827993775719, 'suggest': 2.2187979981117376, 'mani': 2.519827993775719, 'key': 5.039655987551438, 'principl': 5.039655987551438, 'econom': 7.559483981327157, 'thought': 7.559483981327157, 'includ': 5.039655987551438, 'divis': 5.039655987551438, 'labor': 2.519827993775719, 'invis': 7.559483981327157, 'hand': 4.437595996223475, 'seventi': 2.519827993775719, 'year': 1.9177680024477564, 'concept': 2.519827993775719, 'thoroughli': 2.519827993775719, 'elucid': 2.519827993775719, 'adam': 7.559483981327157, 'smith': 10.079311975102875, 'much': 2.519827993775719, 'known': 3.1311709686727878, 'life': 1.741676743392075, 'probabl': 4.437595996223475, 'grew': 2.519827993775719, 'rotterdam': 2.519827993775719, 'netherland': 2.519827993775719, 'son': 2.2187979981117376, 'physician': 3.6417159788794, 'enrol': 2.2187979981117376, 'leiden': 2.519827993775719, 'univers': 1.674729953761462, 'produc': 5.039655987551438, 'thesi': 2.519827993775719, 'de': 3.349459907522924, 'brutorum': 2.519827993775719, 'operationibu': 2.519827993775719, 'advoc': 2.519827993775719, 'cartesian': 2.519827993775719, 'theori': 1.8208579894397, 'automat': 2.2187979981117376, 'among': 2.2187979981117376, 'anim': 2.519827993775719, 'receiv': 2.2187979981117376, 'degre': 2.0427067390560563, 'medicin': 2.2187979981117376, 'disput': 2.519827993775719, 'titl': 2.2187979981117376, 'chylosi': 2.519827993775719, 'vitiata': 2.519827993775719, 'well': 5.753304007343269, 'respect': 2.519827993775719, 'sever': 2.519827993775719, 'literari': 2.2187979981117376, 'work': 3.0396559875514377, 'consid': 1.9177680024477564, 'success': 2.519827993775719, 'grumbl': 2.519827993775719, 'hive': 2.519827993775719, 'publish': 4.437595996223475, 'name': 2.519827993775719, 'privat': 2.519827993775719, 'vice': 5.039655987551438, 'public': 6.656393994335213, 'benefit': 12.599139968878594, 'next': 2.519827993775719, 'mention': 2.2187979981117376, 'poem': 2.519827993775719, 'detail': 2.519827993775719, 'discuss': 2.519827993775719, 'book': 1.9177680024477564, 'consist': 2.519827993775719, 'numer': 2.0427067390560563, 'labour': 2.519827993775719, 'describ': 2.519827993775719, 'commun': 5.039655987551438, 'suddenli': 2.519827993775719, 'turn': 2.519827993775719, 'honest': 2.519827993775719, 'virtuou': 5.039655987551438, 'be': 2.519827993775719, 'collaps': 2.519827993775719, 'due': 2.2187979981117376, 'lack': 2.2187979981117376, 'desir': 2.519827993775719, 'person': 2.519827993775719, 'explain': 2.2187979981117376, 'necessari': 2.2187979981117376, 'prosper': 2.519827993775719, 'quit': 2.2187979981117376, 'scandal': 2.519827993775719, 'point': 2.519827993775719, 'view': 2.519827993775719, 'also': 2.0427067390560563, 'express': 2.519827993775719, 'individu': 2.2187979981117376, 'collect': 2.519827993775719, 'action': 2.519827993775719, 'may': 4.0854134781121125, 'lead': 2.0427067390560563, 'howev': 4.437595996223475, 'believ': 2.0427067390560563, 'result': 5.039655987551438, 'need': 2.0427067390560563, 'someon': 2.519827993775719, 'garner': 2.519827993775719, 'politician': 2.519827993775719, 'ensur': 2.519827993775719, 'peopl': 2.519827993775719, 'passion': 2.2187979981117376, 'realli': 2.2187979981117376, 'back': 2.519827993775719, 'day': 2.2187979981117376, 'idea': 2.2187979981117376, 'seen': 2.519827993775719, 'degrad': 2.519827993775719, 'concern': 2.519827993775719, 'human': 2.519827993775719, 'natur': 2.2187979981117376, 'yovisto': 2.519827993775719, 'interest': 2.2187979981117376, 'video': 2.519827993775719, 'lectur': 2.2187979981117376, 'wealth': 2.519827993775719, 'nation': 2.0427067390560563, 'professor': 2.2187979981117376, 'jame': 1.8208579894397, 'paradi': 2.519827993775719}\n"
     ]
    }
   ],
   "source": [
    "print(weighting_dict[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wes2015.q01.naf',\n",
       " 'wes2015.q02.naf',\n",
       " 'wes2015.q03.naf',\n",
       " 'wes2015.q04.naf',\n",
       " 'wes2015.q06.naf',\n",
       " 'wes2015.q07.naf',\n",
       " 'wes2015.q08.naf',\n",
       " 'wes2015.q09.naf',\n",
       " 'wes2015.q10.naf',\n",
       " 'wes2015.q12.naf',\n",
       " 'wes2015.q13.naf',\n",
       " 'wes2015.q14.naf',\n",
       " 'wes2015.q16.naf',\n",
       " 'wes2015.q17.naf',\n",
       " 'wes2015.q18.naf',\n",
       " 'wes2015.q19.naf',\n",
       " 'wes2015.q22.naf',\n",
       " 'wes2015.q23.naf',\n",
       " 'wes2015.q24.naf',\n",
       " 'wes2015.q25.naf',\n",
       " 'wes2015.q26.naf',\n",
       " 'wes2015.q27.naf',\n",
       " 'wes2015.q28.naf',\n",
       " 'wes2015.q29.naf',\n",
       " 'wes2015.q32.naf',\n",
       " 'wes2015.q34.naf',\n",
       " 'wes2015.q36.naf',\n",
       " 'wes2015.q37.naf',\n",
       " 'wes2015.q38.naf',\n",
       " 'wes2015.q40.naf',\n",
       " 'wes2015.q41.naf',\n",
       " 'wes2015.q42.naf',\n",
       " 'wes2015.q44.naf',\n",
       " 'wes2015.q45.naf',\n",
       " 'wes2015.q46.naf']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the file path for the set of queries in case that the program is set to get a random query from the path set\n",
    "queries_file_path = \"dataset/queries-raw-texts\"\n",
    "\n",
    "# Getting the example queries found under the path set above\n",
    "queries = [f for f in os.listdir(queries_file_path)]\n",
    "\n",
    "# Printing the filenames of the example queries (for testing)\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Get a user query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to parse the XML from a query and extract the content from < raw > tag - used only to get example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query_xml(xml_file_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Find the user query within the XML structure\n",
    "    raw_element = root.find('.//raw')\n",
    "\n",
    "    # Check if the raw element is found\n",
    "    if raw_element is not None:\n",
    "        # Get the text content of the raw element\n",
    "        query = raw_element.text\n",
    "        return query\n",
    "    else:\n",
    "        return \"Raw element not found in the XML structure.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the query. The content of the < nafHeader > tag in each document is stored in a variable called query. A flag is used to tell program if we want a query from the queries subfolder or get the query from user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a query: Astronomy\n",
      "Astronomy\n"
     ]
    }
   ],
   "source": [
    "# Boolean which informs program whether to get random query from queries subfolder\n",
    "get_random_query = False\n",
    "\n",
    "if (get_random_query):    # get random query\n",
    "    index = random.randint(0, len(queries)-1)\n",
    "    print(\"Index chosen: \"+str(index))\n",
    "\n",
    "    xml_file_path = queries_file_path+ '/' +str(queries[index])\n",
    "\n",
    "    query = parse_query_xml(xml_file_path)\n",
    "else:    # ask user to enter query\n",
    "    query = input(\"Enter a query: \")\n",
    "\n",
    "# Printing the query\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Preprocess the query  (tokenisation, case-folding, stop-word removal and stemming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1 - Performing tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Astronomy']\n"
     ]
    }
   ],
   "source": [
    "# Extracting the different tokens from the query\n",
    "query_tokens = nltk.tokenize.word_tokenize(query)\n",
    "\n",
    "# Printing the tokens that got extracted (for testing purposes)\n",
    "print(query_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2 - Performing case folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomy']\n"
     ]
    }
   ],
   "source": [
    "# Converting all the query tokens to lowercase\n",
    "lowercase_query_tokens = [qt.lower() for qt in query_tokens]\n",
    "\n",
    "# Printing the new tokens\n",
    "print(lowercase_query_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering the tokens to only include alphabetical tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomy']\n"
     ]
    }
   ],
   "source": [
    "# Removing any non-alphabetical query tokens\n",
    "alpha_query_tokens = [at for at in lowercase_query_tokens if at.isalpha ()]\n",
    "\n",
    "# Printing the new tokens\n",
    "print(alpha_query_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3 - Performing stop-word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomy']\n"
     ]
    }
   ],
   "source": [
    "# Getting a list of English stop-words\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Removing the stop-words from our tokens\n",
    "filt_query_tokens = [ft for ft in alpha_query_tokens if (not ft in stopwords)]\n",
    "\n",
    "# Printing the filtered tokens\n",
    "print(filt_query_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.4 - Performing stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astronomi']\n"
     ]
    }
   ],
   "source": [
    "# Declaring and initialising a stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "stemmed_query_tokens = [stemmer.stem(t) for t in filt_query_tokens]\n",
    "print(stemmed_query_tokens);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Using cosine similarity to calculate the similarity between query and rach document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating several functions in order to perform several calculations (i.e. cosine similarity, creating a vector and creating a vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(query_vector, document_vector):\n",
    "    # Calculate cosine similarity between two vectors\n",
    "    dot_product = np.dot(query_vector, document_vector)\n",
    "    norm_query = np.linalg.norm(query_vector)\n",
    "    norm_document = np.linalg.norm(document_vector)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if norm_query == 0 or norm_document == 0:\n",
    "        return 0.0\n",
    "\n",
    "    cosine_similarity = dot_product / (norm_query * norm_document)\n",
    "    return cosine_similarity\n",
    "\n",
    "def create_vector(text, vocabulary):\n",
    "    # Create a vector representation of the text based on a vocabulary\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in text:\n",
    "        if word in vocabulary:\n",
    "            vector[vocabulary[word]] += 1\n",
    "    return vector\n",
    "\n",
    "def create_vocabulary(texts):\n",
    "    # Create a vocabulary based on a list of texts\n",
    "    vocabulary = {}\n",
    "    for text in texts:\n",
    "        for word in text:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = len(vocabulary)\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above functions to calculate the similarity between user query and each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list storing the similarity scores since this will be used when outputting list of documents in order\n",
    "similarity_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score with Document 1: 0.0\n",
      "Similarity Score with Document 2: 0.0\n",
      "Similarity Score with Document 3: 0.0\n",
      "Similarity Score with Document 4: 0.0\n",
      "Similarity Score with Document 5: 0.0\n",
      "Similarity Score with Document 6: 0.0\n",
      "Similarity Score with Document 7: 0.0\n",
      "Similarity Score with Document 8: 0.0\n",
      "Similarity Score with Document 9: 0.0\n",
      "Similarity Score with Document 10: 0.0\n",
      "Similarity Score with Document 11: 0.0\n",
      "Similarity Score with Document 12: 0.0\n",
      "Similarity Score with Document 13: 0.0\n",
      "Similarity Score with Document 14: 0.0\n",
      "Similarity Score with Document 15: 0.0\n",
      "Similarity Score with Document 16: 0.0\n",
      "Similarity Score with Document 17: 0.0\n",
      "Similarity Score with Document 18: 0.0\n",
      "Similarity Score with Document 19: 0.0\n",
      "Similarity Score with Document 20: 0.0\n",
      "Similarity Score with Document 21: 0.0\n",
      "Similarity Score with Document 22: 0.0\n",
      "Similarity Score with Document 23: 0.0\n",
      "Similarity Score with Document 24: 0.0\n",
      "Similarity Score with Document 25: 0.0\n",
      "Similarity Score with Document 26: 0.0\n",
      "Similarity Score with Document 27: 0.0\n",
      "Similarity Score with Document 28: 0.0\n",
      "Similarity Score with Document 29: 0.0\n",
      "Similarity Score with Document 30: 0.0\n",
      "Similarity Score with Document 31: 0.07249994335944138\n",
      "Similarity Score with Document 32: 0.0\n",
      "Similarity Score with Document 33: 0.0\n",
      "Similarity Score with Document 34: 0.09307080728365465\n",
      "Similarity Score with Document 35: 0.0\n",
      "Similarity Score with Document 36: 0.0\n",
      "Similarity Score with Document 37: 0.0\n",
      "Similarity Score with Document 38: 0.0\n",
      "Similarity Score with Document 39: 0.022697981217836876\n",
      "Similarity Score with Document 40: 0.04569116623849538\n",
      "Similarity Score with Document 41: 0.0\n",
      "Similarity Score with Document 42: 0.10063092108532552\n",
      "Similarity Score with Document 43: 0.0\n",
      "Similarity Score with Document 44: 0.03225806451612903\n",
      "Similarity Score with Document 45: 0.0\n",
      "Similarity Score with Document 46: 0.0\n",
      "Similarity Score with Document 47: 0.0\n",
      "Similarity Score with Document 48: 0.0\n",
      "Similarity Score with Document 49: 0.0\n",
      "Similarity Score with Document 50: 0.0\n",
      "Similarity Score with Document 51: 0.0\n",
      "Similarity Score with Document 52: 0.0\n",
      "Similarity Score with Document 53: 0.0\n",
      "Similarity Score with Document 54: 0.0\n",
      "Similarity Score with Document 55: 0.0\n",
      "Similarity Score with Document 56: 0.0\n",
      "Similarity Score with Document 57: 0.0\n",
      "Similarity Score with Document 58: 0.0\n",
      "Similarity Score with Document 59: 0.0\n",
      "Similarity Score with Document 60: 0.12216944435630522\n",
      "Similarity Score with Document 61: 0.14285714285714285\n",
      "Similarity Score with Document 62: 0.0\n",
      "Similarity Score with Document 63: 0.0\n",
      "Similarity Score with Document 64: 0.0\n",
      "Similarity Score with Document 65: 0.0\n",
      "Similarity Score with Document 66: 0.0\n",
      "Similarity Score with Document 67: 0.03407990882954985\n",
      "Similarity Score with Document 68: 0.0\n",
      "Similarity Score with Document 69: 0.0\n",
      "Similarity Score with Document 70: 0.0\n",
      "Similarity Score with Document 71: 0.0\n",
      "Similarity Score with Document 72: 0.0\n",
      "Similarity Score with Document 73: 0.0\n",
      "Similarity Score with Document 74: 0.1281682672224003\n",
      "Similarity Score with Document 75: 0.0\n",
      "Similarity Score with Document 76: 0.0\n",
      "Similarity Score with Document 77: 0.0\n",
      "Similarity Score with Document 78: 0.0\n",
      "Similarity Score with Document 79: 0.0\n",
      "Similarity Score with Document 80: 0.10297110457020561\n",
      "Similarity Score with Document 81: 0.0\n",
      "Similarity Score with Document 82: 0.0\n",
      "Similarity Score with Document 83: 0.07317617332646023\n",
      "Similarity Score with Document 84: 0.0\n",
      "Similarity Score with Document 85: 0.0\n",
      "Similarity Score with Document 86: 0.0\n",
      "Similarity Score with Document 87: 0.0\n",
      "Similarity Score with Document 88: 0.09231861823449955\n",
      "Similarity Score with Document 89: 0.0\n",
      "Similarity Score with Document 90: 0.0\n",
      "Similarity Score with Document 91: 0.0\n",
      "Similarity Score with Document 92: 0.0\n",
      "Similarity Score with Document 93: 0.0\n",
      "Similarity Score with Document 94: 0.0\n",
      "Similarity Score with Document 95: 0.0\n",
      "Similarity Score with Document 96: 0.05370216135410547\n",
      "Similarity Score with Document 97: 0.0\n",
      "Similarity Score with Document 98: 0.10222859593214292\n",
      "Similarity Score with Document 99: 0.12869789041755736\n",
      "Similarity Score with Document 100: 0.0\n",
      "Similarity Score with Document 101: 0.0\n",
      "Similarity Score with Document 102: 0.0\n",
      "Similarity Score with Document 103: 0.0\n",
      "Similarity Score with Document 104: 0.0\n",
      "Similarity Score with Document 105: 0.0\n",
      "Similarity Score with Document 106: 0.0\n",
      "Similarity Score with Document 107: 0.0\n",
      "Similarity Score with Document 108: 0.0\n",
      "Similarity Score with Document 109: 0.0\n",
      "Similarity Score with Document 110: 0.0\n",
      "Similarity Score with Document 111: 0.0\n",
      "Similarity Score with Document 112: 0.0646508183835236\n",
      "Similarity Score with Document 113: 0.0\n",
      "Similarity Score with Document 114: 0.0\n",
      "Similarity Score with Document 115: 0.0\n",
      "Similarity Score with Document 116: 0.0\n",
      "Similarity Score with Document 117: 0.0\n",
      "Similarity Score with Document 118: 0.0\n",
      "Similarity Score with Document 119: 0.0\n",
      "Similarity Score with Document 120: 0.0\n",
      "Similarity Score with Document 121: 0.0\n",
      "Similarity Score with Document 122: 0.0\n",
      "Similarity Score with Document 123: 0.051383499553870796\n",
      "Similarity Score with Document 124: 0.0\n",
      "Similarity Score with Document 125: 0.0\n",
      "Similarity Score with Document 126: 0.0\n",
      "Similarity Score with Document 127: 0.0\n",
      "Similarity Score with Document 128: 0.0\n",
      "Similarity Score with Document 129: 0.0604122093330177\n",
      "Similarity Score with Document 130: 0.0\n",
      "Similarity Score with Document 131: 0.0\n",
      "Similarity Score with Document 132: 0.0\n",
      "Similarity Score with Document 133: 0.0\n",
      "Similarity Score with Document 134: 0.0\n",
      "Similarity Score with Document 135: 0.06544199910036884\n",
      "Similarity Score with Document 136: 0.0\n",
      "Similarity Score with Document 137: 0.0\n",
      "Similarity Score with Document 138: 0.0\n",
      "Similarity Score with Document 139: 0.0\n",
      "Similarity Score with Document 140: 0.0\n",
      "Similarity Score with Document 141: 0.0\n",
      "Similarity Score with Document 142: 0.0\n",
      "Similarity Score with Document 143: 0.0\n",
      "Similarity Score with Document 144: 0.0\n",
      "Similarity Score with Document 145: 0.0\n",
      "Similarity Score with Document 146: 0.0\n",
      "Similarity Score with Document 147: 0.0\n",
      "Similarity Score with Document 148: 0.0\n",
      "Similarity Score with Document 149: 0.0\n",
      "Similarity Score with Document 150: 0.0\n",
      "Similarity Score with Document 151: 0.12898007411770432\n",
      "Similarity Score with Document 152: 0.0\n",
      "Similarity Score with Document 153: 0.0\n",
      "Similarity Score with Document 154: 0.0\n",
      "Similarity Score with Document 155: 0.0\n",
      "Similarity Score with Document 156: 0.0\n",
      "Similarity Score with Document 157: 0.0\n",
      "Similarity Score with Document 158: 0.0\n",
      "Similarity Score with Document 159: 0.0\n",
      "Similarity Score with Document 160: 0.0\n",
      "Similarity Score with Document 161: 0.0\n",
      "Similarity Score with Document 162: 0.0\n",
      "Similarity Score with Document 163: 0.0\n",
      "Similarity Score with Document 164: 0.0\n",
      "Similarity Score with Document 165: 0.0288314965852446\n",
      "Similarity Score with Document 166: 0.0\n",
      "Similarity Score with Document 167: 0.0\n",
      "Similarity Score with Document 168: 0.0\n",
      "Similarity Score with Document 169: 0.0\n",
      "Similarity Score with Document 170: 0.0\n",
      "Similarity Score with Document 171: 0.0\n",
      "Similarity Score with Document 172: 0.0\n",
      "Similarity Score with Document 173: 0.0\n",
      "Similarity Score with Document 174: 0.0\n",
      "Similarity Score with Document 175: 0.0\n",
      "Similarity Score with Document 176: 0.0\n",
      "Similarity Score with Document 177: 0.0\n",
      "Similarity Score with Document 178: 0.0\n",
      "Similarity Score with Document 179: 0.0\n",
      "Similarity Score with Document 180: 0.0\n",
      "Similarity Score with Document 181: 0.03460642701029914\n",
      "Similarity Score with Document 182: 0.0\n",
      "Similarity Score with Document 183: 0.0\n",
      "Similarity Score with Document 184: 0.0\n",
      "Similarity Score with Document 185: 0.0\n",
      "Similarity Score with Document 186: 0.0\n",
      "Similarity Score with Document 187: 0.0\n",
      "Similarity Score with Document 188: 0.0\n",
      "Similarity Score with Document 189: 0.0\n",
      "Similarity Score with Document 190: 0.0\n",
      "Similarity Score with Document 191: 0.0\n",
      "Similarity Score with Document 192: 0.0\n",
      "Similarity Score with Document 193: 0.0\n",
      "Similarity Score with Document 194: 0.0\n",
      "Similarity Score with Document 195: 0.0\n",
      "Similarity Score with Document 196: 0.0\n",
      "Similarity Score with Document 197: 0.0\n",
      "Similarity Score with Document 198: 0.0\n",
      "Similarity Score with Document 199: 0.0\n",
      "Similarity Score with Document 200: 0.0\n",
      "Similarity Score with Document 201: 0.0\n",
      "Similarity Score with Document 202: 0.0\n",
      "Similarity Score with Document 203: 0.0\n",
      "Similarity Score with Document 204: 0.0\n",
      "Similarity Score with Document 205: 0.0\n",
      "Similarity Score with Document 206: 0.0\n",
      "Similarity Score with Document 207: 0.0\n",
      "Similarity Score with Document 208: 0.0\n",
      "Similarity Score with Document 209: 0.0\n",
      "Similarity Score with Document 210: 0.0\n",
      "Similarity Score with Document 211: 0.0\n",
      "Similarity Score with Document 212: 0.0\n",
      "Similarity Score with Document 213: 0.0\n",
      "Similarity Score with Document 214: 0.0\n",
      "Similarity Score with Document 215: 0.0\n",
      "Similarity Score with Document 216: 0.0\n",
      "Similarity Score with Document 217: 0.0\n",
      "Similarity Score with Document 218: 0.0\n",
      "Similarity Score with Document 219: 0.0\n",
      "Similarity Score with Document 220: 0.0\n",
      "Similarity Score with Document 221: 0.0413802944301184\n",
      "Similarity Score with Document 222: 0.0\n",
      "Similarity Score with Document 223: 0.0\n",
      "Similarity Score with Document 224: 0.0\n",
      "Similarity Score with Document 225: 0.0\n",
      "Similarity Score with Document 226: 0.0\n",
      "Similarity Score with Document 227: 0.0\n",
      "Similarity Score with Document 228: 0.0\n",
      "Similarity Score with Document 229: 0.03187883565316691\n",
      "Similarity Score with Document 230: 0.0\n",
      "Similarity Score with Document 231: 0.0\n",
      "Similarity Score with Document 232: 0.0\n",
      "Similarity Score with Document 233: 0.0\n",
      "Similarity Score with Document 234: 0.023537557657892522\n",
      "Similarity Score with Document 235: 0.0\n",
      "Similarity Score with Document 236: 0.0\n",
      "Similarity Score with Document 237: 0.04920678313051229\n",
      "Similarity Score with Document 238: 0.0\n",
      "Similarity Score with Document 239: 0.0\n",
      "Similarity Score with Document 240: 0.03331483023263848\n",
      "Similarity Score with Document 241: 0.0\n",
      "Similarity Score with Document 242: 0.0\n",
      "Similarity Score with Document 243: 0.18578433666678973\n",
      "Similarity Score with Document 244: 0.0\n",
      "Similarity Score with Document 245: 0.0\n",
      "Similarity Score with Document 246: 0.0\n",
      "Similarity Score with Document 247: 0.0\n",
      "Similarity Score with Document 248: 0.0\n",
      "Similarity Score with Document 249: 0.0\n",
      "Similarity Score with Document 250: 0.0\n",
      "Similarity Score with Document 251: 0.0\n",
      "Similarity Score with Document 252: 0.0\n",
      "Similarity Score with Document 253: 0.06608186004550898\n",
      "Similarity Score with Document 254: 0.0\n",
      "Similarity Score with Document 255: 0.064183054380568\n",
      "Similarity Score with Document 256: 0.0\n",
      "Similarity Score with Document 257: 0.0\n",
      "Similarity Score with Document 258: 0.0\n",
      "Similarity Score with Document 259: 0.0\n",
      "Similarity Score with Document 260: 0.0\n",
      "Similarity Score with Document 261: 0.0\n",
      "Similarity Score with Document 262: 0.044455422447438706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score with Document 263: 0.023796037813647444\n",
      "Similarity Score with Document 264: 0.0\n",
      "Similarity Score with Document 265: 0.031992834407549194\n",
      "Similarity Score with Document 266: 0.0\n",
      "Similarity Score with Document 267: 0.0\n",
      "Similarity Score with Document 268: 0.0\n",
      "Similarity Score with Document 269: 0.0\n",
      "Similarity Score with Document 270: 0.0\n",
      "Similarity Score with Document 271: 0.0\n",
      "Similarity Score with Document 272: 0.0\n",
      "Similarity Score with Document 273: 0.0\n",
      "Similarity Score with Document 274: 0.07357118927777097\n",
      "Similarity Score with Document 275: 0.0\n",
      "Similarity Score with Document 276: 0.0\n",
      "Similarity Score with Document 277: 0.0\n",
      "Similarity Score with Document 278: 0.0\n",
      "Similarity Score with Document 279: 0.0\n",
      "Similarity Score with Document 280: 0.0\n",
      "Similarity Score with Document 281: 0.04981354813867179\n",
      "Similarity Score with Document 282: 0.09467916046467048\n",
      "Similarity Score with Document 283: 0.0\n",
      "Similarity Score with Document 284: 0.0\n",
      "Similarity Score with Document 285: 0.0\n",
      "Similarity Score with Document 286: 0.0\n",
      "Similarity Score with Document 287: 0.0\n",
      "Similarity Score with Document 288: 0.0\n",
      "Similarity Score with Document 289: 0.04719291781830087\n",
      "Similarity Score with Document 290: 0.0\n",
      "Similarity Score with Document 291: 0.0\n",
      "Similarity Score with Document 292: 0.0\n",
      "Similarity Score with Document 293: 0.0\n",
      "Similarity Score with Document 294: 0.021471887546694362\n",
      "Similarity Score with Document 295: 0.0\n",
      "Similarity Score with Document 296: 0.0\n",
      "Similarity Score with Document 297: 0.0\n",
      "Similarity Score with Document 298: 0.0\n",
      "Similarity Score with Document 299: 0.0\n",
      "Similarity Score with Document 300: 0.0\n",
      "Similarity Score with Document 301: 0.0\n",
      "Similarity Score with Document 302: 0.0\n",
      "Similarity Score with Document 303: 0.0\n",
      "Similarity Score with Document 304: 0.0\n",
      "Similarity Score with Document 305: 0.0\n",
      "Similarity Score with Document 306: 0.0\n",
      "Similarity Score with Document 307: 0.0\n",
      "Similarity Score with Document 308: 0.0\n",
      "Similarity Score with Document 309: 0.0\n",
      "Similarity Score with Document 310: 0.0\n",
      "Similarity Score with Document 311: 0.03806934938134405\n",
      "Similarity Score with Document 312: 0.0\n",
      "Similarity Score with Document 313: 0.0\n",
      "Similarity Score with Document 314: 0.0\n",
      "Similarity Score with Document 315: 0.0\n",
      "Similarity Score with Document 316: 0.0\n",
      "Similarity Score with Document 317: 0.0\n",
      "Similarity Score with Document 318: 0.0\n",
      "Similarity Score with Document 319: 0.0\n",
      "Similarity Score with Document 320: 0.0\n",
      "Similarity Score with Document 321: 0.0\n",
      "Similarity Score with Document 322: 0.0\n",
      "Similarity Score with Document 323: 0.0\n",
      "Similarity Score with Document 324: 0.0\n",
      "Similarity Score with Document 325: 0.0\n",
      "Similarity Score with Document 326: 0.0\n",
      "Similarity Score with Document 327: 0.0\n",
      "Similarity Score with Document 328: 0.0\n",
      "Similarity Score with Document 329: 0.0\n",
      "Similarity Score with Document 330: 0.0\n",
      "Similarity Score with Document 331: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Create a vocabulary\n",
    "for i in range(0, len(xml_docs_tokens)):\n",
    "    all_texts = [stemmed_query_tokens] + [xml_docs_tokens[i]]\n",
    "    \n",
    "    vocabulary = create_vocabulary(all_texts)\n",
    "\n",
    "    # Create vectors for user query and documents\n",
    "    query_vector = create_vector(stemmed_query_tokens, vocabulary)\n",
    "    document_vectors = create_vector(xml_docs_tokens[i], vocabulary)\n",
    "\n",
    "    # Calculate cosine similarity with each document\n",
    "    similarity_scores = calculate_cosine_similarity(query_vector, document_vectors)\n",
    "    similarity_list.append(similarity_scores)\n",
    "    print(\"Similarity Score with Document \"+str((i+1))+\": \"+str(similarity_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Outputting the list of documents as a ranked list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function, similar to the one used to parse the XML from a document, but this time to the content from < fileDesc > tag under the < nafHeader > tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_doc_title(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # This is assuming that the document only contains one <nafHeader> tag in the XML document\n",
    "    file_desc_element = root.find(\".//nafHeader/fileDesc\")\n",
    "    \n",
    "    # Getting the title from the <nafHeader> tag\n",
    "    raw_data = file_desc_element.get(\"title\")\n",
    "\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing all the documents found in the dataset subfolder. The content of the < fileDesc > tag in each document is stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to store the document titles\n",
    "docs_titles = []\n",
    "\n",
    "# Loop through each document to get its title\n",
    "for doc in docs:\n",
    "    file_path = docs_file_path+ '/' +str(doc)\n",
    "    \n",
    "    raw_data = parse_doc_title(file_path)\n",
    "    \n",
    "    docs_titles.append(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the contents of the fileDesc tag - for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernard Mandeville and the Fable of the Bees\n"
     ]
    }
   ],
   "source": [
    "print(docs_titles[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary which stores the document titles and their respective similarity scores. This is useful when actually sorting the titles by their score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = dict()\n",
    "\n",
    "for i in range(0, len(docs_titles)):\n",
    "    score_dict.update({docs_titles[i]: similarity_list[i]})\n",
    "\n",
    "\n",
    "# Printing the contents from the dictionary (for testing purposes)\n",
    "#print(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting the similarity scores list in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked List of Documents:\n",
      "1. Document: Johannes Hevelius and his Selenographia\n",
      "Similarity Score: 0.18578433666678973\n",
      "\n",
      "2. Document: Fred Whipple and the Dirty Snowballs\n",
      "Similarity Score: 0.14285714285714285\n",
      "\n",
      "3. Document: Johann Heinrich von Mädler and the First Accurate Map of the Moon\n",
      "Similarity Score: 0.12898007411770432\n",
      "\n",
      "4. Document: Jean Picard and his Love for Accuracy\n",
      "Similarity Score: 0.12869789041755736\n",
      "\n",
      "5. Document: Pierre Mechain and the Meridian Survey Expedition\n",
      "Similarity Score: 0.1281682672224003\n",
      "\n",
      "6. Document: Sir Bernard Lovell and the Radioastronomy\n",
      "Similarity Score: 0.12216944435630522\n",
      "\n",
      "7. Document: Abu Ma’shar al-Balkhi – The Prince of Astrologers\n",
      "Similarity Score: 0.10297110457020561\n",
      "\n",
      "8. Document: Friedrich Bessel and the Distances of Stars\n",
      "Similarity Score: 0.10222859593214292\n",
      "\n",
      "9. Document: Heinrich Olbers and the Olbers’ Paradox\n",
      "Similarity Score: 0.10063092108532552\n",
      "\n",
      "10. Document: Ulugh Beg – Astronomer\n",
      "Similarity Score: 0.09467916046467048\n",
      "\n",
      "11. Document: Eudoxus and the Method of Exhaustion\n",
      "Similarity Score: 0.09307080728365465\n",
      "\n",
      "12. Document: Maria Mitchell and the Comets\n",
      "Similarity Score: 0.09231861823449955\n",
      "\n",
      "13. Document: Henry Draper and his Passion for Astronomy\n",
      "Similarity Score: 0.07357118927777097\n",
      "\n",
      "14. Document: Girolamo Fracastoro’s Germ Theory\n",
      "Similarity Score: 0.07317617332646023\n",
      "\n",
      "15. Document: The Planetary Tables of Erasmus Reinhold\n",
      "Similarity Score: 0.07249994335944138\n",
      "\n",
      "16. Document: Fritz Zwicky and the Dark Matter\n",
      "Similarity Score: 0.06608186004550898\n",
      "\n",
      "17. Document: Charles Augustin de Coulomb and the Electrostatic Force\n",
      "Similarity Score: 0.06544199910036884\n",
      "\n",
      "18. Document: Rudolf Wolf and the Sunspots\n",
      "Similarity Score: 0.0646508183835236\n",
      "\n",
      "19. Document: Georg Joachim Rheticus’ Achievements for Astronomy\n",
      "Similarity Score: 0.064183054380568\n",
      "\n",
      "20. Document: Gerald Hawkins and the Secret of Stonehenge\n",
      "Similarity Score: 0.0604122093330177\n",
      "\n",
      "21. Document: Joseph Nicollet and the Upper Mississippi River\n",
      "Similarity Score: 0.05370216135410547\n",
      "\n",
      "22. Document: Lyman Spitzer and the Space Telescope\n",
      "Similarity Score: 0.051383499553870796\n",
      "\n",
      "23. Document: The Life and Work of Philippe de La Hire\n",
      "Similarity Score: 0.04981354813867179\n",
      "\n",
      "24. Document: Andrija Mohorovičić and the Mohorovičić Discontinuity\n",
      "Similarity Score: 0.04920678313051229\n",
      "\n",
      "25. Document: John Goodricke and the Variable Star of Beta Persei\n",
      "Similarity Score: 0.04719291781830087\n",
      "\n",
      "26. Document: Peter Barlow and the Barlow Lenses\n",
      "Similarity Score: 0.04569116623849538\n",
      "\n",
      "27. Document: Nikolai Lobachevsky – The Copernicus of Geometry\n",
      "Similarity Score: 0.044455422447438706\n",
      "\n",
      "28. Document: Let Us Calculate – the Last Universal Academic Gottfried Wilhelm Leibniz\n",
      "Similarity Score: 0.0413802944301184\n",
      "\n",
      "29. Document: El Escorial – The World’s largest Renaissance Building\n",
      "Similarity Score: 0.03806934938134405\n",
      "\n",
      "30. Document: Henri Poincaré – the Last Universalist of Mathematics\n",
      "Similarity Score: 0.03460642701029914\n",
      "\n",
      "31. Document: Pliny the Elder and the Destruction of Pompeii\n",
      "Similarity Score: 0.03407990882954985\n",
      "\n",
      "32. Document: Henry Briggs and the Popularization on Logarithms\n",
      "Similarity Score: 0.03331483023263848\n",
      "\n",
      "33. Document: Karl Schwarzschild and the Event Horizon\n",
      "Similarity Score: 0.03225806451612903\n",
      "\n",
      "34. Document: Samuel Pierpont Langley and his Aviation Work\n",
      "Similarity Score: 0.031992834407549194\n",
      "\n",
      "35. Document: Johannes Schöner and his Globes\n",
      "Similarity Score: 0.03187883565316691\n",
      "\n",
      "36. Document: Francis Baily and the Baily Beads\n",
      "Similarity Score: 0.0288314965852446\n",
      "\n",
      "37. Document: Camille Flammarion and his Balancing Act between Popular Science and Science Fiction\n",
      "Similarity Score: 0.023796037813647444\n",
      "\n",
      "38. Document: Simon Marius and his Astronomical Discoveries\n",
      "Similarity Score: 0.023537557657892522\n",
      "\n",
      "39. Document: Pythagoras and his Eponymous Theorem\n",
      "Similarity Score: 0.022697981217836876\n",
      "\n",
      "40. Document: The Visions of Emanuel Swedenborg\n",
      "Similarity Score: 0.021471887546694362\n",
      "\n",
      "41. Document: William Beaumont and the Human Digestion\n",
      "Similarity Score: 0.0\n",
      "\n",
      "42. Document: Selma Lagerlöf and the wonderful Adventures of Niels Holgersson\n",
      "Similarity Score: 0.0\n",
      "\n",
      "43. Document: Ferdinand de Lesseps and the Suez Canal\n",
      "Similarity Score: 0.0\n",
      "\n",
      "44. Document: Walt Disney’s ‘Steamboat Willie’ and the Rise of Mickey Mouse\n",
      "Similarity Score: 0.0\n",
      "\n",
      "45. Document: Eugene Wigner and the Structure of the Atomic Nucleus\n",
      "Similarity Score: 0.0\n",
      "\n",
      "46. Document: Eugenio Beltrami and Non-Euclidian Geometry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "47. Document: Bernard Mandeville and the Fable of the Bees\n",
      "Similarity Score: 0.0\n",
      "\n",
      "48. Document: Leo Baekeland and the Beginning of the Plastic Age\n",
      "Similarity Score: 0.0\n",
      "\n",
      "49. Document: Dorothea Erxleben – Germany’s First Female Medical Doctor\n",
      "Similarity Score: 0.0\n",
      "\n",
      "50. Document: Sir James Young Simpson and the Chloroform\n",
      "Similarity Score: 0.0\n",
      "\n",
      "51. Document: Louis Antoine de Bougainville and his Voyage Around the World\n",
      "Similarity Score: 0.0\n",
      "\n",
      "52. Document: Robert Morison and the Classification of Plants\n",
      "Similarity Score: 0.0\n",
      "\n",
      "53. Document: Florence Sabin – Preparing the Ground for Women in Medical Science\n",
      "Similarity Score: 0.0\n",
      "\n",
      "54. Document: Hermann ‘Klecks’ Rorschach and his Eponymous Test\n",
      "Similarity Score: 0.0\n",
      "\n",
      "55. Document: William Stukeley and the Mystery of Stonehenge\n",
      "Similarity Score: 0.0\n",
      "\n",
      "56. Document: Adolphe Sax and the Saxophone\n",
      "Similarity Score: 0.0\n",
      "\n",
      "57. Document: Edvard Munch and the Munch Affair\n",
      "Similarity Score: 0.0\n",
      "\n",
      "58. Document: Spyridon Marinatos and the Discovery of Akrotiri\n",
      "Similarity Score: 0.0\n",
      "\n",
      "59. Document: Daniel Rutherford and the isolation of Nitrogen\n",
      "Similarity Score: 0.0\n",
      "\n",
      "60. Document: Alexander Lippisch and the Delta Wing\n",
      "Similarity Score: 0.0\n",
      "\n",
      "61. Document: Oskar Barnack – the Father of 35mm Photography\n",
      "Similarity Score: 0.0\n",
      "\n",
      "62. Document: Adolf von Baeyer and the Color Blue\n",
      "Similarity Score: 0.0\n",
      "\n",
      "63. Document: Hans Grade – German Aviation Pioneer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "64. Document: Othniel Charles Marsh and the Great Bone Wars\n",
      "Similarity Score: 0.0\n",
      "\n",
      "65. Document: Constantine and the Battle at the Milvian Bridge\n",
      "Similarity Score: 0.0\n",
      "\n",
      "66. Document: Jean-Rondolphe Perronet and the Bridges of Paris\n",
      "Similarity Score: 0.0\n",
      "\n",
      "67. Document: Giovanni Maria Lancisi and his Medical Discoveries\n",
      "Similarity Score: 0.0\n",
      "\n",
      "68. Document: William Higinbotham and Tennis for Two\n",
      "Similarity Score: 0.0\n",
      "\n",
      "69. Document: Charles Joseph Minard and the Art of Infographics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "70. Document: Felix Bloch and the Nuclear Magnetic Resonance Method\n",
      "Similarity Score: 0.0\n",
      "\n",
      "71. Document: Samuel W. Alderson and the Crash Test Dummies\n",
      "Similarity Score: 0.0\n",
      "\n",
      "72. Document: Vannoccio Biringuccio and the Art of Metalworking\n",
      "Similarity Score: 0.0\n",
      "\n",
      "73. Document: Nicholas Culpeper and the Complete Herbs of England\n",
      "Similarity Score: 0.0\n",
      "\n",
      "74. Document: Socrates and the Socratic Method\n",
      "Similarity Score: 0.0\n",
      "\n",
      "75. Document: Albrecht von Haller – Father of Modern Physiology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "76. Document: Evangelista Torricelli and the Barometer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "77. Document: Ascanio Sobrero and the Power of Nitroglycerine\n",
      "Similarity Score: 0.0\n",
      "\n",
      "78. Document: Henry Cavendish and the Weight of the Earth\n",
      "Similarity Score: 0.0\n",
      "\n",
      "79. Document: Thales of Miletus – (possibly) the Father of Greek Mathematics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "80. Document: Richard Leuckart and the Tapeworm\n",
      "Similarity Score: 0.0\n",
      "\n",
      "81. Document: Richard Dedekind and the Real Numbers\n",
      "Similarity Score: 0.0\n",
      "\n",
      "82. Document: Robert Goddard – the Man who ushered in the Space Age\n",
      "Similarity Score: 0.0\n",
      "\n",
      "83. Document: James Lind and a Cure for Scurvy\n",
      "Similarity Score: 0.0\n",
      "\n",
      "84. Document: Sir Patrick Manson – The Father of Tropical Medicine\n",
      "Similarity Score: 0.0\n",
      "\n",
      "85. Document: Willy Ley – Founder of the German Rocket Society\n",
      "Similarity Score: 0.0\n",
      "\n",
      "86. Document: The Unfortunate Inventions of Charles Cros\n",
      "Similarity Score: 0.0\n",
      "\n",
      "87. Document: Étienne de Condillac and the Importance of Language in Logical Reasoning\n",
      "Similarity Score: 0.0\n",
      "\n",
      "88. Document: Fritz Kahn and the Mensch Maschine\n",
      "Similarity Score: 0.0\n",
      "\n",
      "89. Document: William F. Friedman and the Art of Cryptology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "90. Document: The Travels of William Dampier\n",
      "Similarity Score: 0.0\n",
      "\n",
      "91. Document: Louis Henry Sullivan – the ‘Father’ of the Skyscaper\n",
      "Similarity Score: 0.0\n",
      "\n",
      "92. Document: Ernst Curtius and the Excavation of Olympia\n",
      "Similarity Score: 0.0\n",
      "\n",
      "93. Document: Sergei Winogradsky and the Science of Bacteriology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "94. Document: Werner Forssmann and the dangerous Self Experiment in Cardiac Catheterization\n",
      "Similarity Score: 0.0\n",
      "\n",
      "95. Document: Antoine Cournot and the Mathematical Theory of Economics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "96. Document: Man Ray and the Art of Photograms\n",
      "Similarity Score: 0.0\n",
      "\n",
      "97. Document: Lee De Forest and the Audion\n",
      "Similarity Score: 0.0\n",
      "\n",
      "98. Document: Elizabeth Montagu and the Bluestocking Society\n",
      "Similarity Score: 0.0\n",
      "\n",
      "99. Document: Paul Nipkow and the Picture Scanning Technology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "100. Document: William Murdock ‘enlights’ the 19th Century\n",
      "Similarity Score: 0.0\n",
      "\n",
      "101. Document: Jöns Jacob Berzelius – One of the Founders of Modern Chemistry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "102. Document: Philo Taylor Farnsworth and the Electronic Television\n",
      "Similarity Score: 0.0\n",
      "\n",
      "103. Document: Brook Taylor – Forerunner of Differential Calculus\n",
      "Similarity Score: 0.0\n",
      "\n",
      "104. Document: Hazel Bishop and the Long Lasting Lipstick\n",
      "Similarity Score: 0.0\n",
      "\n",
      "105. Document: Louis de Broglie and wave nature of matter\n",
      "Similarity Score: 0.0\n",
      "\n",
      "106. Document: John Logie Baird and the Television\n",
      "Similarity Score: 0.0\n",
      "\n",
      "107. Document: The Art of Suspense – Alfred Hitchcock’s Cinema\n",
      "Similarity Score: 0.0\n",
      "\n",
      "108. Document: Meet Sue, the Dinosaur\n",
      "Similarity Score: 0.0\n",
      "\n",
      "109. Document: Richard Mead and the Understanding of Transmissible Diseases\n",
      "Similarity Score: 0.0\n",
      "\n",
      "110. Document: Ernest Lawrence and the Cyclotron\n",
      "Similarity Score: 0.0\n",
      "\n",
      "111. Document: Victor Franz Hess and the Cosmic Radiation\n",
      "Similarity Score: 0.0\n",
      "\n",
      "112. Document: Joseph Carey Merrick – the Elefant Man\n",
      "Similarity Score: 0.0\n",
      "\n",
      "113. Document: Nicolas-Jacques Conté and the Pencil\n",
      "Similarity Score: 0.0\n",
      "\n",
      "114. Document: Richard Arkwright – the Father of the Industrial Revolution\n",
      "Similarity Score: 0.0\n",
      "\n",
      "115. Document: John Tyndall and the Physics of Air\n",
      "Similarity Score: 0.0\n",
      "\n",
      "116. Document: Stephanie Kwolek and the Bullet-proof Vests\n",
      "Similarity Score: 0.0\n",
      "\n",
      "117. Document: Marius and the Battle of the Raudine Plain\n",
      "Similarity Score: 0.0\n",
      "\n",
      "118. Document: Dorothy Hodgkin and the Structure of Penicilin\n",
      "Similarity Score: 0.0\n",
      "\n",
      "119. Document: Karl Popper and the Philosophy of Science\n",
      "Similarity Score: 0.0\n",
      "\n",
      "120. Document: Rosalind Franklin and the Beauty of the DNA Structure\n",
      "Similarity Score: 0.0\n",
      "\n",
      "121. Document: The Plays of George Bernard Shaw\n",
      "Similarity Score: 0.0\n",
      "\n",
      "122. Document: Thomas Say and his Love for Beetles\n",
      "Similarity Score: 0.0\n",
      "\n",
      "123. Document: Isaac Singer and the Sewing Machine\n",
      "Similarity Score: 0.0\n",
      "\n",
      "124. Document: Sir John Reith and the BBC\n",
      "Similarity Score: 0.0\n",
      "\n",
      "125. Document: The Dancers of Edgar Degas\n",
      "Similarity Score: 0.0\n",
      "\n",
      "126. Document: William Makepeace Thackeray’s deft Skewering of Human Foibles\n",
      "Similarity Score: 0.0\n",
      "\n",
      "127. Document: The World of Lyonel Feininger\n",
      "Similarity Score: 0.0\n",
      "\n",
      "128. Document: Pavel Cherenkov and the Blue Light\n",
      "Similarity Score: 0.0\n",
      "\n",
      "129. Document: The Conversational Eloquence of Madame de Staël\n",
      "Similarity Score: 0.0\n",
      "\n",
      "130. Document: August Kekulé and the Carbon Ring Structure\n",
      "Similarity Score: 0.0\n",
      "\n",
      "131. Document: Pablo Picasso’s Guernica\n",
      "Similarity Score: 0.0\n",
      "\n",
      "132. Document: Samuel Goudsmit and the Electron Spin\n",
      "Similarity Score: 0.0\n",
      "\n",
      "133. Document: Camille Pissaro and the Impressionistic Art Movement\n",
      "Similarity Score: 0.0\n",
      "\n",
      "134. Document: John Wheeler and the Golden Age of General Relativity\n",
      "Similarity Score: 0.0\n",
      "\n",
      "135. Document: Alfred Binet and the Intelligence Test\n",
      "Similarity Score: 0.0\n",
      "\n",
      "136. Document: Albert von Kölliker and the Origins of Embriology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "137. Document: A. E. Douglass and the Dendrochronology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "138. Document: Rube Goldberg’s complicated Machines\n",
      "Similarity Score: 0.0\n",
      "\n",
      "139. Document: Ottmar Mergenthaler – a Second Gutenberg\n",
      "Similarity Score: 0.0\n",
      "\n",
      "140. Document: Hans Bethe and the Energy of the Stars\n",
      "Similarity Score: 0.0\n",
      "\n",
      "141. Document: Ignaz Semmelweis and the Importance of Washing Your Hands as a Doctor\n",
      "Similarity Score: 0.0\n",
      "\n",
      "142. Document: Adolf Furtwängler and Photographic Archeology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "143. Document: Rembert Dodoens and the Love for Botanical Science\n",
      "Similarity Score: 0.0\n",
      "\n",
      "144. Document: Maria Goeppert Mayer and the Nuclear Shell Model\n",
      "Similarity Score: 0.0\n",
      "\n",
      "145. Document: Sophie Germain and the Chladni Experiment\n",
      "Similarity Score: 0.0\n",
      "\n",
      "146. Document: Hermann Oberth’s Dream of Space Travel\n",
      "Similarity Score: 0.0\n",
      "\n",
      "147. Document: Martin Perl and the Tau\n",
      "Similarity Score: 0.0\n",
      "\n",
      "148. Document: Deodat de Dolomieu and the Love for Rocks\n",
      "Similarity Score: 0.0\n",
      "\n",
      "149. Document: The Discovery of Charon\n",
      "Similarity Score: 0.0\n",
      "\n",
      "150. Document: Franz Kruckenberg’s Schienenzeppelin\n",
      "Similarity Score: 0.0\n",
      "\n",
      "151. Document: Ernst Boris Chain and his Research on Antibiotics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "152. Document: Jürgen Habermas and Communicative Rationality\n",
      "Similarity Score: 0.0\n",
      "\n",
      "153. Document: Sir Francis Drake’s discovery of Nova Albion\n",
      "Similarity Score: 0.0\n",
      "\n",
      "154. Document: Barbara McClintock and Cytogenetics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "155. Document: Niemand hat die Absicht eine Mauer zu bauen!\n",
      "Similarity Score: 0.0\n",
      "\n",
      "156. Document: William Butler Yeats and Modern English Literature\n",
      "Similarity Score: 0.0\n",
      "\n",
      "157. Document: The Diary of Anne Frank\n",
      "Similarity Score: 0.0\n",
      "\n",
      "158. Document: The Hayden Geological Survey and the Yellowstone National Park\n",
      "Similarity Score: 0.0\n",
      "\n",
      "159. Document: Life and Legend of Frederick Barbarossa\n",
      "Similarity Score: 0.0\n",
      "\n",
      "160. Document: Johann Gottfried Galle and Planet Neptune\n",
      "Similarity Score: 0.0\n",
      "\n",
      "161. Document: The Viking Raid on the Abbey of Lindisfarne\n",
      "Similarity Score: 0.0\n",
      "\n",
      "162. Document: Robert Mulliken and the Molecular Orbitals\n",
      "Similarity Score: 0.0\n",
      "\n",
      "163. Document: Thomas Mann and the Mann Family\n",
      "Similarity Score: 0.0\n",
      "\n",
      "164. Document: The Bose-Einstein Condensate brings Quantum Theory to the Macroscopic Scale\n",
      "Similarity Score: 0.0\n",
      "\n",
      "165. Document: The First Pulitzer Prize\n",
      "Similarity Score: 0.0\n",
      "\n",
      "166. Document: The First American to walk in Space – Edward White\n",
      "Similarity Score: 0.0\n",
      "\n",
      "167. Document: The Novels of Thomas Hardy\n",
      "Similarity Score: 0.0\n",
      "\n",
      "168. Document: Carnot and Thermodynamics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "169. Document: The Poetry of Walt Whitman\n",
      "Similarity Score: 0.0\n",
      "\n",
      "170. Document: Elly Beinhorn and her Love for Aviation\n",
      "Similarity Score: 0.0\n",
      "\n",
      "171. Document: Thomas Moore – Ireland’s National Bard\n",
      "Similarity Score: 0.0\n",
      "\n",
      "172. Document: Niccoló Paganini – the Devil’s Violinist\n",
      "Similarity Score: 0.0\n",
      "\n",
      "173. Document: August von Parseval`s Airships\n",
      "Similarity Score: 0.0\n",
      "\n",
      "174. Document: The First US Space Station Skylab\n",
      "Similarity Score: 0.0\n",
      "\n",
      "175. Document: Aviatrix Amy Johnson and the Flight to Australia\n",
      "Similarity Score: 0.0\n",
      "\n",
      "176. Document: The Legend of Bonnie and Clyde\n",
      "Similarity Score: 0.0\n",
      "\n",
      "177. Document: Hergé and the Adventures of Tintin\n",
      "Similarity Score: 0.0\n",
      "\n",
      "178. Document: Marcel Breuer – Master of Modernism\n",
      "Similarity Score: 0.0\n",
      "\n",
      "179. Document: Abraham Ortelius and the Theatrum Orbis Terrarum\n",
      "Similarity Score: 0.0\n",
      "\n",
      "180. Document: Alcuin of York and the Carolingian Renaissance\n",
      "Similarity Score: 0.0\n",
      "\n",
      "181. Document: Beaumarchais and Figaro's Wedding\n",
      "Similarity Score: 0.0\n",
      "\n",
      "182. Document: The Myserious Voynich Manuscript\n",
      "Similarity Score: 0.0\n",
      "\n",
      "183. Document: The Phantastic Travels of Adelbert von Chamisso\n",
      "Similarity Score: 0.0\n",
      "\n",
      "184. Document: The Airplanes of Claude Dornier\n",
      "Similarity Score: 0.0\n",
      "\n",
      "185. Document: Igor Sikorsky and the Helicopter\n",
      "Similarity Score: 0.0\n",
      "\n",
      "186. Document: Florence Nightingale – The Lady with the Lamp\n",
      "Similarity Score: 0.0\n",
      "\n",
      "187. Document: The very first Printed Book\n",
      "Similarity Score: 0.0\n",
      "\n",
      "188. Document: Caspar Monge and the Geometry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "189. Document: Thomas Blood and the Crown Jewels of England\n",
      "Similarity Score: 0.0\n",
      "\n",
      "190. Document: Mary the Jewess and the Origins of Chemistry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "191. Document: Carl Hagenbeck and the Modern Zoo\n",
      "Similarity Score: 0.0\n",
      "\n",
      "192. Document: Adolph von Knigge and Human Relations\n",
      "Similarity Score: 0.0\n",
      "\n",
      "193. Document: You Press the Button and We Do the Rest – George Eastman revolutionized Photography\n",
      "Similarity Score: 0.0\n",
      "\n",
      "194. Document: How the Pope divided the New World among Spain and the Rest of the World\n",
      "Similarity Score: 0.0\n",
      "\n",
      "195. Document: SPAM Rules the Internet\n",
      "Similarity Score: 0.0\n",
      "\n",
      "196. Document: Johann Carolus and the First Newspaper\n",
      "Similarity Score: 0.0\n",
      "\n",
      "197. Document: Orson Welles’ Citizen Kane\n",
      "Similarity Score: 0.0\n",
      "\n",
      "198. Document: J. J. Thompson and the Electron\n",
      "Similarity Score: 0.0\n",
      "\n",
      "199. Document: Dennis Tito, Space Tourist\n",
      "Similarity Score: 0.0\n",
      "\n",
      "200. Document: Edward Whymper and the Matterhorn\n",
      "Similarity Score: 0.0\n",
      "\n",
      "201. Document: John James Audubon’s Birds of America\n",
      "Similarity Score: 0.0\n",
      "\n",
      "202. Document: Claude Joseph Rouget de Lisle and the Marseillaise\n",
      "Similarity Score: 0.0\n",
      "\n",
      "203. Document: Laurens Hammond and the Hammond Organ\n",
      "Similarity Score: 0.0\n",
      "\n",
      "204. Document: The German Reinheitsgebot\n",
      "Similarity Score: 0.0\n",
      "\n",
      "205. Document: Encore un Moment – The Life of Madame Du Barry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "206. Document: Sir George Stokes and Fluid Dynamics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "207. Document: Gideon Mantell and the Iguanodon\n",
      "Similarity Score: 0.0\n",
      "\n",
      "208. Document: John Lindley and his Love for Plants\n",
      "Similarity Score: 0.0\n",
      "\n",
      "209. Document: John McCarthy and the Raise of Artificial Intelligence\n",
      "Similarity Score: 0.0\n",
      "\n",
      "210. Document: E.F. Codd and the Relational Database Model\n",
      "Similarity Score: 0.0\n",
      "\n",
      "211. Document: Marvin Minsky and Artificial Neural Networks\n",
      "Similarity Score: 0.0\n",
      "\n",
      "212. Document: Dan Bricklin and VisiCalc\n",
      "Similarity Score: 0.0\n",
      "\n",
      "213. Document: The Antikythera Mechanism – an Ancient Analog Computer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "214. Document: Rudy Rucker – Infinity and the Mind\n",
      "Similarity Score: 0.0\n",
      "\n",
      "215. Document: J.C.R. Licklider and Interactive Computing\n",
      "Similarity Score: 0.0\n",
      "\n",
      "216. Document: The Birth of the Internet\n",
      "Similarity Score: 0.0\n",
      "\n",
      "217. Document: The Last Lecture of Randy Pausch\n",
      "Similarity Score: 0.0\n",
      "\n",
      "218. Document: FORTRAN – The First Programming Language for Numeric Calculations\n",
      "Similarity Score: 0.0\n",
      "\n",
      "219. Document: John Atanasoff and the first Electronic Digital Computer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "220. Document: GNU’s not Unix\n",
      "Similarity Score: 0.0\n",
      "\n",
      "221. Document: Space Invaders!\n",
      "Similarity Score: 0.0\n",
      "\n",
      "222. Document: Vannevar Bush and the Memex\n",
      "Similarity Score: 0.0\n",
      "\n",
      "223. Document: Amusing Ourselves to Death by Neil Postman\n",
      "Similarity Score: 0.0\n",
      "\n",
      "224. Document: Nikolaus Wirth and PASCAL\n",
      "Similarity Score: 0.0\n",
      "\n",
      "225. Document: ENIAC – The First Computer Introduced Into Public\n",
      "Similarity Score: 0.0\n",
      "\n",
      "226. Document: Donald Knuth and the Art of Programming\n",
      "Similarity Score: 0.0\n",
      "\n",
      "227. Document: Joseph Weizenbaum and his famous Eliza\n",
      "Similarity Score: 0.0\n",
      "\n",
      "228. Document: Konrad Zuse – The Inventor of the Computer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "229. Document: George Boole – The Founder of Modern Logics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "230. Document: Doug Engelbart and the Computer Mouse\n",
      "Similarity Score: 0.0\n",
      "\n",
      "231. Document: Intel 4004 – The World’s First Microprocessor\n",
      "Similarity Score: 0.0\n",
      "\n",
      "232. Document: Charles Babbage – The Father of the Computer who hated Street Music\n",
      "Similarity Score: 0.0\n",
      "\n",
      "233. Document: Dennis Ritchie – Designer of UNIX and C\n",
      "Similarity Score: 0.0\n",
      "\n",
      "234. Document: “Don’t be evil” – Google celebrates its 14th Birthday\n",
      "Similarity Score: 0.0\n",
      "\n",
      "235. Document: Happy Birthday Linux!\n",
      "Similarity Score: 0.0\n",
      "\n",
      "236. Document: The Bug that wasn’t really a Bug – Computer Pioneer Grace Murray Hopper\n",
      "Similarity Score: 0.0\n",
      "\n",
      "237. Document: It's Computable - thanks to Alonzo Church\n",
      "Similarity Score: 0.0\n",
      "\n",
      "238. Document: Churchill’s Best Horse in the Barn – Alan Turing, Codebreaker and AI Pioneer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "239. Document: Well, I Didn’t Know it was Hard – Happy Birthday Ivan Sutherland\n",
      "Similarity Score: 0.0\n",
      "\n",
      "240. Document: Do You Speak Polish… Or Maybe Reverse Polish?\n",
      "Similarity Score: 0.0\n",
      "\n",
      "241. Document: Claude Shannon – Father of Information Theory\n",
      "Similarity Score: 0.0\n",
      "\n",
      "242. Document: Nicolas Steno and the Principles of Modern Geology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "243. Document: Alfred Tarski and the Undefinability of Truth\n",
      "Similarity Score: 0.0\n",
      "\n",
      "244. Document: Friedrich Schiller ‘The Robbers’\n",
      "Similarity Score: 0.0\n",
      "\n",
      "245. Document: Lewis Terman and the Intelligence Quotient\n",
      "Similarity Score: 0.0\n",
      "\n",
      "246. Document: Thomas Augustus Watson – Recipient of the Very First Phone Call\n",
      "Similarity Score: 0.0\n",
      "\n",
      "247. Document: Gaspard Bauhin and the Classification of Plants\n",
      "Similarity Score: 0.0\n",
      "\n",
      "248. Document: The Steel of Sir Henry Bessemer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "249. Document: Pierre Gassendi and his Trials to reconcile Epicurean atomism with Christianity\n",
      "Similarity Score: 0.0\n",
      "\n",
      "250. Document: John Fitch and the Steam Boat\n",
      "Similarity Score: 0.0\n",
      "\n",
      "251. Document: Oskar Morgenstern and the Game Theory\n",
      "Similarity Score: 0.0\n",
      "\n",
      "252. Document: Fabian von Bellingshausen and the Discovery of Antarctica\n",
      "Similarity Score: 0.0\n",
      "\n",
      "253. Document: Thomas Willis and the Royal Society\n",
      "Similarity Score: 0.0\n",
      "\n",
      "254. Document: Ernst Kummer and his Achievements in Mathematics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "255. Document: Euclid – the Father of Geometry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "256. Document: Charles Green and his Record Balloon Flight\n",
      "Similarity Score: 0.0\n",
      "\n",
      "257. Document: Dmitri Mendeleev and the Periodic Table of Elements\n",
      "Similarity Score: 0.0\n",
      "\n",
      "258. Document: Charles Lindbergh and his Spirit of St. Louis\n",
      "Similarity Score: 0.0\n",
      "\n",
      "259. Document: Joseph Priestley and the Discovery of Oxygen\n",
      "Similarity Score: 0.0\n",
      "\n",
      "260. Document: Alfred Adler and the Individual Psychology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "261. Document: Erich von Drygalski’s Antarctic Expeditions\n",
      "Similarity Score: 0.0\n",
      "\n",
      "262. Document: Leo Szilard and the Atomic Bomb\n",
      "Similarity Score: 0.0\n",
      "\n",
      "263. Document: Lejeune Dirichlet and the Mathematical Function\n",
      "Similarity Score: 0.0\n",
      "\n",
      "264. Document: Henry Steinway and the Grand Pianos\n",
      "Similarity Score: 0.0\n",
      "\n",
      "265. Document: Frederick Eugene Ives and the Halftone Printing Process\n",
      "Similarity Score: 0.0\n",
      "\n",
      "266. Document: Octave Chanute – One of the Fathers of Aviation\n",
      "Similarity Score: 0.0\n",
      "\n",
      "267. Document: Robert E. Peary’s Arctic Expedition\n",
      "Similarity Score: 0.0\n",
      "\n",
      "268. Document: John Mercer and the Cotton Mercerisation\n",
      "Similarity Score: 0.0\n",
      "\n",
      "269. Document: Frank P. Ramsey and the Ramsey Theory\n",
      "Similarity Score: 0.0\n",
      "\n",
      "270. Document: Andrea Cesalpino and the Classification of Plants\n",
      "Similarity Score: 0.0\n",
      "\n",
      "271. Document: Giovanni Battista Morgagni and the Science of Anatomy\n",
      "Similarity Score: 0.0\n",
      "\n",
      "272. Document: A life is like a garden – Leonard Nimoy\n",
      "Similarity Score: 0.0\n",
      "\n",
      "273. Document: Robert Cornelius shoots the very first Selfie\n",
      "Similarity Score: 0.0\n",
      "\n",
      "274. Document: Walter Bruch and the PAL Color Television System\n",
      "Similarity Score: 0.0\n",
      "\n",
      "275. Document: Jeremias Richter and the Law of Definite Proportions\n",
      "Similarity Score: 0.0\n",
      "\n",
      "276. Document: John Murray and the Oceanography\n",
      "Similarity Score: 0.0\n",
      "\n",
      "277. Document: George Gamow and his fundamental Views on the Foundations of Science\n",
      "Similarity Score: 0.0\n",
      "\n",
      "278. Document: The Philosophical Transactions of the Royal Society\n",
      "Similarity Score: 0.0\n",
      "\n",
      "279. Document: William Oughtred and the Slide Rule\n",
      "Similarity Score: 0.0\n",
      "\n",
      "280. Document: John Fothergill – Physician and Gardener\n",
      "Similarity Score: 0.0\n",
      "\n",
      "281. Document: Howard H. Aiken and the Harvard Mark I\n",
      "Similarity Score: 0.0\n",
      "\n",
      "282. Document: Richard E. Byrd, Jr. – Aviator and Polar Explorer\n",
      "Similarity Score: 0.0\n",
      "\n",
      "283. Document: Vladimir Vernadsky and the Biosphere\n",
      "Similarity Score: 0.0\n",
      "\n",
      "284. Document: Joseph Priestley – The Educator and Historian\n",
      "Similarity Score: 0.0\n",
      "\n",
      "285. Document: Frederick Reines and the Neutrino\n",
      "Similarity Score: 0.0\n",
      "\n",
      "286. Document: Georg Friedrich Philipp von Hardenberg aka Novalis\n",
      "Similarity Score: 0.0\n",
      "\n",
      "287. Document: Aristarchus of Samos and the Heliocentric System\n",
      "Similarity Score: 0.0\n",
      "\n",
      "288. Document: Hippolyte Fizeau and the Speed of Light\n",
      "Similarity Score: 0.0\n",
      "\n",
      "289. Document: James Dewar and the Liquefaction of Gases\n",
      "Similarity Score: 0.0\n",
      "\n",
      "290. Document: How Ötzi became World Famous\n",
      "Similarity Score: 0.0\n",
      "\n",
      "291. Document: Legendre’s Elements of Geometry\n",
      "Similarity Score: 0.0\n",
      "\n",
      "292. Document: Bernard Siegfried Albinus and his Anatomic Works\n",
      "Similarity Score: 0.0\n",
      "\n",
      "293. Document: August Wilhelm Schlegel and his Shakespeare Translations\n",
      "Similarity Score: 0.0\n",
      "\n",
      "294. Document: John Dalton and the Atomic Theory\n",
      "Similarity Score: 0.0\n",
      "\n",
      "295. Document: The Works of Heinrich Mann\n",
      "Similarity Score: 0.0\n",
      "\n",
      "296. Document: Jethro Tull and the Agricultural Revolution\n",
      "Similarity Score: 0.0\n",
      "\n",
      "297. Document: The psychologist must study mankind from the historical or comparative standpoint – Moritz Lazarus\n",
      "Similarity Score: 0.0\n",
      "\n",
      "298. Document: The Sydney Harbour Bridge\n",
      "Similarity Score: 0.0\n",
      "\n",
      "299. Document: B.F. Skinner and Radical Behaviorism\n",
      "Similarity Score: 0.0\n",
      "\n",
      "300. Document: The watches of Daniel Quare\n",
      "Similarity Score: 0.0\n",
      "\n",
      "301. Document: Erich Fromm and the Frankfurt School of Critical Theory\n",
      "Similarity Score: 0.0\n",
      "\n",
      "302. Document: Vanguard 1 – the first Solar Powered Satellite\n",
      "Similarity Score: 0.0\n",
      "\n",
      "303. Document: The Expeditions of John Wesley Powell\n",
      "Similarity Score: 0.0\n",
      "\n",
      "304. Document: Seymour R. Cray – the Father of Supercomputing\n",
      "Similarity Score: 0.0\n",
      "\n",
      "305. Document: Joseph Proust and the Law of Constant Composition\n",
      "Similarity Score: 0.0\n",
      "\n",
      "306. Document: Abraham Werner and the School of Neptunism\n",
      "Similarity Score: 0.0\n",
      "\n",
      "307. Document: Georg Simmel – First Generation Sociologist\n",
      "Similarity Score: 0.0\n",
      "\n",
      "308. Document: Carl Jacobi and the Elliptic Functions\n",
      "Similarity Score: 0.0\n",
      "\n",
      "309. Document: Paul Ehrlich and the Chemotherapy\n",
      "Similarity Score: 0.0\n",
      "\n",
      "310. Document: John Snow and His Work on Cholera\n",
      "Similarity Score: 0.0\n",
      "\n",
      "311. Document: William Budd and the Infectious Diseases\n",
      "Similarity Score: 0.0\n",
      "\n",
      "312. Document: Harvey Fletcher – the Father of Stereophonic Sound\n",
      "Similarity Score: 0.0\n",
      "\n",
      "313. Document: Jacques de Perthes and European Archaeology\n",
      "Similarity Score: 0.0\n",
      "\n",
      "314. Document: Pavlov and the Conditional Reflex\n",
      "Similarity Score: 0.0\n",
      "\n",
      "315. Document: The First Spacecraft to Land on the Moon – Luna 2\n",
      "Similarity Score: 0.0\n",
      "\n",
      "316. Document: The Passionate Life of Charlotte Brontë\n",
      "Similarity Score: 0.0\n",
      "\n",
      "317. Document: Royal Botanist Charles Plumier\n",
      "Similarity Score: 0.0\n",
      "\n",
      "318. Document: August Wilhelm Iffland and the Iffland Ring\n",
      "Similarity Score: 0.0\n",
      "\n",
      "319. Document: The Natural History Museum in London\n",
      "Similarity Score: 0.0\n",
      "\n",
      "320. Document: William Wilson and the First German Railway\n",
      "Similarity Score: 0.0\n",
      "\n",
      "321. Document: Aviation Pioneer Harriet Quimby\n",
      "Similarity Score: 0.0\n",
      "\n",
      "322. Document: Samuel Johnson and his Famous Dictionary\n",
      "Similarity Score: 0.0\n",
      "\n",
      "323. Document: The Kinetoscope and Edison’s Wrong Way to Invent the Cinema\n",
      "Similarity Score: 0.0\n",
      "\n",
      "324. Document: Catherine de Medici and St. Bartholomew’s Day\n",
      "Similarity Score: 0.0\n",
      "\n",
      "325. Document: Robert Delaunay and Orphism\n",
      "Similarity Score: 0.0\n",
      "\n",
      "326. Document: Vom Science Slam zur Bestsellerliste\n",
      "Similarity Score: 0.0\n",
      "\n",
      "327. Document: James Parkinson and Parkinson’s Disease\n",
      "Similarity Score: 0.0\n",
      "\n",
      "328. Document: Juan de la Cierva and the Autogiro\n",
      "Similarity Score: 0.0\n",
      "\n",
      "329. Document: Squire Whipple – The Father of the Iron Bridge\n",
      "Similarity Score: 0.0\n",
      "\n",
      "330. Document: William Playfair and the Beginnings of Infographics\n",
      "Similarity Score: 0.0\n",
      "\n",
      "331. Document: Juan Bautista de Anza and the Route to San Francisco Bay\n",
      "Similarity Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort dictionary in descending order\n",
    "doc_titles_ranked = sorted(score_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "# Output the ranked list of documents (including those with 0 similarity)\n",
    "counter = 1\n",
    "\n",
    "print(\"Ranked List of Documents:\")\n",
    "\n",
    "# Looping through the dictionary and print each document in order with its score\n",
    "for x,y in doc_titles_ranked:\n",
    "    print(str(counter)+ \". Document: \"+str(x)+ \"\\nSimilarity Score: \"+str(y)+\"\\n\")\n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Matthias Vassallo Pulis"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "title": "ICS2205 - Web Intelligence - Individual Project Part 1 - Information Retrieval"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
